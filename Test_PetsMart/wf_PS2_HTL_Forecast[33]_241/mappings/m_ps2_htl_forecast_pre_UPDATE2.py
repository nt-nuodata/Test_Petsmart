# Databricks notebook source
# MAGIC %run "./udf_informatica"

# COMMAND ----------


from pyspark.sql.types import *

spark.sql("use DELTA_TRAINING")
spark.sql("set spark.sql.legacy.timeParserPolicy = LEGACY")

# COMMAND ----------
%run ./MappingUtility

# COMMAND ----------
mainWorkflowId = dbutils.widgets.get("mainWorkflowId")
mainWorkflowRunId = dbutils.widgets.get("mainWorkflowRunId")
parentName = dbutils.widgets.get("parentName")
preVariableAssignment = dbutils.widgets.get("preVariableAssignment")
postVariableAssignment = dbutils.widgets.get("postVariableAssignment")
truncTargetTableOptions = dbutils.widgets.get("truncTargetTableOptions")
variablesTableName = dbutils.widgets.get("variablesTableName")

# COMMAND ----------
#Truncate Target Tables
truncateTargetTables(truncTargetTableOptions)

# COMMAND ----------
#Pre presession variable updation
updateVariable(preVariableAssignment, variablesTableName, mainWorkflowId, parentName, "m_ps2_htl_forecast_pre_UPDATE2")

# COMMAND ----------
fetchAndCreateVariables(parentName,"m_ps2_htl_forecast_pre_UPDATE2", variablesTableName, mainWorkflowId)

# COMMAND ----------
# DBTITLE 1, Shortcut_to_PS2_HTL_ETL_CONTROL_0


query_0 = f"""SELECT
  PS2_HTL_PROCESS_ID AS PS2_HTL_PROCESS_ID,
  PS2_HTL_PROCESS_DESC AS PS2_HTL_PROCESS_DESC,
  PS2_HTL_RUN_DT AS PS2_HTL_RUN_DT,
  UPDATE_TSTMP AS UPDATE_TSTMP
FROM
  PS2_HTL_ETL_CONTROL"""

df_0 = spark.sql(query_0)

df_0.createOrReplaceTempView("Shortcut_to_PS2_HTL_ETL_CONTROL_0")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_PS2_HTL_ETL_CONTROL1_1


query_1 = f"""SELECT
  PS2_HTL_PROCESS_ID AS PS2_HTL_PROCESS_ID,
  PS2_HTL_PROCESS_DESC AS PS2_HTL_PROCESS_DESC,
  PS2_HTL_RUN_DT AS PS2_HTL_RUN_DT,
  UPDATE_TSTMP AS UPDATE_TSTMP
FROM
  PS2_HTL_ETL_CONTROL"""

df_1 = spark.sql(query_1)

df_1.createOrReplaceTempView("Shortcut_to_PS2_HTL_ETL_CONTROL1_1")

# COMMAND ----------
# DBTITLE 1, LY_Shortcut_to_PS2_HTL_ETL_CONTROL111_2


query_2 = f"""SELECT
  PS2_HTL_PROCESS_ID AS PS2_HTL_PROCESS_ID,
  PS2_HTL_PROCESS_DESC AS PS2_HTL_PROCESS_DESC,
  PS2_HTL_RUN_DT AS PS2_HTL_RUN_DT,
  UPDATE_TSTMP AS UPDATE_TSTMP
FROM
  PS2_HTL_ETL_CONTROL"""

df_2 = spark.sql(query_2)

df_2.createOrReplaceTempView("LY_Shortcut_to_PS2_HTL_ETL_CONTROL111_2")

# COMMAND ----------
# DBTITLE 1, LY_Shortcut_to_PS2_HTL_ETL_CONTROL11_3


query_3 = f"""SELECT
  PS2_HTL_PROCESS_ID AS PS2_HTL_PROCESS_ID,
  PS2_HTL_PROCESS_DESC AS PS2_HTL_PROCESS_DESC,
  PS2_HTL_RUN_DT AS PS2_HTL_RUN_DT,
  UPDATE_TSTMP AS UPDATE_TSTMP
FROM
  PS2_HTL_ETL_CONTROL"""

df_3 = spark.sql(query_3)

df_3.createOrReplaceTempView("LY_Shortcut_to_PS2_HTL_ETL_CONTROL11_3")

# COMMAND ----------
# DBTITLE 1, LY_Shortcut_to_PS2_HTL_ETL_CONTROL1_4


query_4 = f"""SELECT
  PS2_HTL_PROCESS_ID AS PS2_HTL_PROCESS_ID,
  PS2_HTL_PROCESS_DESC AS PS2_HTL_PROCESS_DESC,
  PS2_HTL_RUN_DT AS PS2_HTL_RUN_DT,
  UPDATE_TSTMP AS UPDATE_TSTMP
FROM
  PS2_HTL_ETL_CONTROL"""

df_4 = spark.sql(query_4)

df_4.createOrReplaceTempView("LY_Shortcut_to_PS2_HTL_ETL_CONTROL1_4")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_PS2_HTL_ETL_CONTROL11_5


query_5 = f"""SELECT
  PS2_HTL_PROCESS_ID AS PS2_HTL_PROCESS_ID,
  PS2_HTL_PROCESS_DESC AS PS2_HTL_PROCESS_DESC,
  PS2_HTL_RUN_DT AS PS2_HTL_RUN_DT,
  UPDATE_TSTMP AS UPDATE_TSTMP
FROM
  PS2_HTL_ETL_CONTROL"""

df_5 = spark.sql(query_5)

df_5.createOrReplaceTempView("Shortcut_to_PS2_HTL_ETL_CONTROL11_5")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_PS2_HTL_OCCUPANCY_DATA_DEFAULT_6


query_6 = f"""SELECT
  DAY_DT AS DAY_DT,
  DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  OVERNIGHT_KITTY_GUEST AS OVERNIGHT_KITTY_GUEST,
  OVERNIGHT_DOG_GUEST AS OVERNIGHT_DOG_GUEST,
  OVERNIGHT_WITH_DDC AS OVERNIGHT_WITH_DDC,
  DAY_CAMP_CNT AS DAY_CAMP_CNT,
  DAY_CARE_CNT AS DAY_CARE_CNT
FROM
  PS2_HTL_OCCUPANCY_DATA_DEFAULT"""

df_6 = spark.sql(query_6)

df_6.createOrReplaceTempView("Shortcut_to_PS2_HTL_OCCUPANCY_DATA_DEFAULT_6")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_PS2_HTL_OCCUPANCY_DATA_DEFAULT1_7


query_7 = f"""SELECT
  DAY_DT AS DAY_DT,
  DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  OVERNIGHT_KITTY_GUEST AS OVERNIGHT_KITTY_GUEST,
  OVERNIGHT_DOG_GUEST AS OVERNIGHT_DOG_GUEST,
  OVERNIGHT_WITH_DDC AS OVERNIGHT_WITH_DDC,
  DAY_CAMP_CNT AS DAY_CAMP_CNT,
  DAY_CARE_CNT AS DAY_CARE_CNT
FROM
  PS2_HTL_OCCUPANCY_DATA_DEFAULT"""

df_7 = spark.sql(query_7)

df_7.createOrReplaceTempView("Shortcut_to_PS2_HTL_OCCUPANCY_DATA_DEFAULT1_7")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_PS2_HTL_OCCUPANCY_DATA_DEFAULT11_8


query_8 = f"""SELECT
  DAY_DT AS DAY_DT,
  DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  OVERNIGHT_KITTY_GUEST AS OVERNIGHT_KITTY_GUEST,
  OVERNIGHT_DOG_GUEST AS OVERNIGHT_DOG_GUEST,
  OVERNIGHT_WITH_DDC AS OVERNIGHT_WITH_DDC,
  DAY_CAMP_CNT AS DAY_CAMP_CNT,
  DAY_CARE_CNT AS DAY_CARE_CNT
FROM
  PS2_HTL_OCCUPANCY_DATA_DEFAULT"""

df_8 = spark.sql(query_8)

df_8.createOrReplaceTempView("Shortcut_to_PS2_HTL_OCCUPANCY_DATA_DEFAULT11_8")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_PS2_DAYS_TY_LY_9


query_9 = f"""SELECT
  DAY_DT AS DAY_DT,
  TRANS_DAY_DT AS TRANS_DAY_DT,
  WEEK_DT AS WEEK_DT,
  FISCAL_YR AS FISCAL_YR,
  TY_LY_FLAG AS TY_LY_FLAG,
  COMP_IND AS COMP_IND
FROM
  PS2_DAYS_TY_LY"""

df_9 = spark.sql(query_9)

df_9.createOrReplaceTempView("Shortcut_to_PS2_DAYS_TY_LY_9")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_PS2_DAYS_TY_LY1_10


query_10 = f"""SELECT
  DAY_DT AS DAY_DT,
  TRANS_DAY_DT AS TRANS_DAY_DT,
  WEEK_DT AS WEEK_DT,
  FISCAL_YR AS FISCAL_YR,
  TY_LY_FLAG AS TY_LY_FLAG,
  COMP_IND AS COMP_IND
FROM
  PS2_DAYS_TY_LY"""

df_10 = spark.sql(query_10)

df_10.createOrReplaceTempView("Shortcut_to_PS2_DAYS_TY_LY1_10")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_TP_SERVICE_SCHEDULE_11


query_11 = f"""SELECT
  DAY_DT AS DAY_DT,
  LOCATION_ID AS LOCATION_ID,
  TP_INVOICE_NBR AS TP_INVOICE_NBR,
  UPC_ID AS UPC_ID,
  SERVICE_ITEM_ID AS SERVICE_ITEM_ID,
  FOLIO_STATUS_FLAG AS FOLIO_STATUS_FLAG,
  PRODUCT_ID AS PRODUCT_ID,
  ROOM_NUMBER AS ROOM_NUMBER,
  ROOM_TYPE_ID AS ROOM_TYPE_ID,
  SERVICE_SCHEDULE_QTY AS SERVICE_SCHEDULE_QTY,
  SERVICE_FREQ_ID AS SERVICE_FREQ_ID,
  LOAD_DT AS LOAD_DT
FROM
  TP_SERVICE_SCHEDULE"""

df_11 = spark.sql(query_11)

df_11.createOrReplaceTempView("Shortcut_to_TP_SERVICE_SCHEDULE_11")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_TP_SERVICE_SCHEDULE1_12


query_12 = f"""SELECT
  DAY_DT AS DAY_DT,
  LOCATION_ID AS LOCATION_ID,
  TP_INVOICE_NBR AS TP_INVOICE_NBR,
  UPC_ID AS UPC_ID,
  SERVICE_ITEM_ID AS SERVICE_ITEM_ID,
  FOLIO_STATUS_FLAG AS FOLIO_STATUS_FLAG,
  PRODUCT_ID AS PRODUCT_ID,
  ROOM_NUMBER AS ROOM_NUMBER,
  ROOM_TYPE_ID AS ROOM_TYPE_ID,
  SERVICE_SCHEDULE_QTY AS SERVICE_SCHEDULE_QTY,
  SERVICE_FREQ_ID AS SERVICE_FREQ_ID,
  LOAD_DT AS LOAD_DT
FROM
  TP_SERVICE_SCHEDULE"""

df_12 = spark.sql(query_12)

df_12.createOrReplaceTempView("Shortcut_to_TP_SERVICE_SCHEDULE1_12")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_TP_SERVICE_SCHEDULE11_13


query_13 = f"""SELECT
  DAY_DT AS DAY_DT,
  LOCATION_ID AS LOCATION_ID,
  TP_INVOICE_NBR AS TP_INVOICE_NBR,
  UPC_ID AS UPC_ID,
  SERVICE_ITEM_ID AS SERVICE_ITEM_ID,
  FOLIO_STATUS_FLAG AS FOLIO_STATUS_FLAG,
  PRODUCT_ID AS PRODUCT_ID,
  ROOM_NUMBER AS ROOM_NUMBER,
  ROOM_TYPE_ID AS ROOM_TYPE_ID,
  SERVICE_SCHEDULE_QTY AS SERVICE_SCHEDULE_QTY,
  SERVICE_FREQ_ID AS SERVICE_FREQ_ID,
  LOAD_DT AS LOAD_DT
FROM
  TP_SERVICE_SCHEDULE"""

df_13 = spark.sql(query_13)

df_13.createOrReplaceTempView("Shortcut_to_TP_SERVICE_SCHEDULE11_13")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_SALES_DAY_SKU_STORE_RPT111_14


query_14 = f"""SELECT
  DAY_DT AS DAY_DT,
  PRODUCT_ID AS PRODUCT_ID,
  LOCATION_ID AS LOCATION_ID,
  SALES_CUST_CAPTURE_CD AS SALES_CUST_CAPTURE_CD,
  WEEK_DT AS WEEK_DT,
  FISCAL_YR AS FISCAL_YR,
  SKU_NBR AS SKU_NBR,
  STORE_NBR AS STORE_NBR,
  OPT_SALES_TYPE_ID AS OPT_SALES_TYPE_ID,
  VENDOR_ID AS VENDOR_ID,
  PROMO_FLAG AS PROMO_FLAG,
  STATUS_ID AS STATUS_ID,
  BRAND_NAME AS BRAND_NAME,
  OWNBRAND_FLAG AS OWNBRAND_FLAG,
  SKU_VEND_TXN_CNT AS SKU_VEND_TXN_CNT,
  NET_SALES_AMT AS NET_SALES_AMT,
  NET_SALES_QTY AS NET_SALES_QTY,
  NET_MARGIN_AMT AS NET_MARGIN_AMT,
  SALES_AMT AS SALES_AMT,
  SALES_COST AS SALES_COST,
  SALES_QTY AS SALES_QTY,
  RETURN_AMT AS RETURN_AMT,
  RETURN_COST AS RETURN_COST,
  RETURN_QTY AS RETURN_QTY,
  CLEARANCE_AMT AS CLEARANCE_AMT,
  CLEARANCE_QTY AS CLEARANCE_QTY,
  CLEARANCE_RETURN_AMT AS CLEARANCE_RETURN_AMT,
  CLEARANCE_RETURN_QTY AS CLEARANCE_RETURN_QTY,
  DISCOUNT_AMT AS DISCOUNT_AMT,
  DISCOUNT_QTY AS DISCOUNT_QTY,
  DISCOUNT_RETURN_AMT AS DISCOUNT_RETURN_AMT,
  DISCOUNT_RETURN_QTY AS DISCOUNT_RETURN_QTY,
  POS_COUPON_AMT AS POS_COUPON_AMT,
  POS_COUPON_QTY AS POS_COUPON_QTY,
  SPECIAL_SALES_AMT AS SPECIAL_SALES_AMT,
  SPECIAL_SALES_QTY AS SPECIAL_SALES_QTY,
  SPECIAL_RETURN_AMT AS SPECIAL_RETURN_AMT,
  SPECIAL_RETURN_QTY AS SPECIAL_RETURN_QTY,
  SPECIAL_SRVC_AMT AS SPECIAL_SRVC_AMT,
  SPECIAL_SRVC_QTY AS SPECIAL_SRVC_QTY,
  MA_SALES_AMT AS MA_SALES_AMT,
  MA_SALES_QTY AS MA_SALES_QTY,
  MA_TRANS_AMT AS MA_TRANS_AMT,
  MA_TRANS_COST AS MA_TRANS_COST,
  MA_TRANS_QTY AS MA_TRANS_QTY,
  EXCH_RATE_PCT AS EXCH_RATE_PCT,
  UPDATE_DT AS UPDATE_DT,
  LOAD_DT AS LOAD_DT
FROM
  SALES_DAY_SKU_STORE_RPT"""

df_14 = spark.sql(query_14)

df_14.createOrReplaceTempView("Shortcut_to_SALES_DAY_SKU_STORE_RPT111_14")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_SALES_DAY_SKU_STORE_RPT1_15


query_15 = f"""SELECT
  DAY_DT AS DAY_DT,
  PRODUCT_ID AS PRODUCT_ID,
  LOCATION_ID AS LOCATION_ID,
  SALES_CUST_CAPTURE_CD AS SALES_CUST_CAPTURE_CD,
  WEEK_DT AS WEEK_DT,
  FISCAL_YR AS FISCAL_YR,
  SKU_NBR AS SKU_NBR,
  STORE_NBR AS STORE_NBR,
  OPT_SALES_TYPE_ID AS OPT_SALES_TYPE_ID,
  VENDOR_ID AS VENDOR_ID,
  PROMO_FLAG AS PROMO_FLAG,
  STATUS_ID AS STATUS_ID,
  BRAND_NAME AS BRAND_NAME,
  OWNBRAND_FLAG AS OWNBRAND_FLAG,
  SKU_VEND_TXN_CNT AS SKU_VEND_TXN_CNT,
  NET_SALES_AMT AS NET_SALES_AMT,
  NET_SALES_QTY AS NET_SALES_QTY,
  NET_MARGIN_AMT AS NET_MARGIN_AMT,
  SALES_AMT AS SALES_AMT,
  SALES_COST AS SALES_COST,
  SALES_QTY AS SALES_QTY,
  RETURN_AMT AS RETURN_AMT,
  RETURN_COST AS RETURN_COST,
  RETURN_QTY AS RETURN_QTY,
  CLEARANCE_AMT AS CLEARANCE_AMT,
  CLEARANCE_QTY AS CLEARANCE_QTY,
  CLEARANCE_RETURN_AMT AS CLEARANCE_RETURN_AMT,
  CLEARANCE_RETURN_QTY AS CLEARANCE_RETURN_QTY,
  DISCOUNT_AMT AS DISCOUNT_AMT,
  DISCOUNT_QTY AS DISCOUNT_QTY,
  DISCOUNT_RETURN_AMT AS DISCOUNT_RETURN_AMT,
  DISCOUNT_RETURN_QTY AS DISCOUNT_RETURN_QTY,
  POS_COUPON_AMT AS POS_COUPON_AMT,
  POS_COUPON_QTY AS POS_COUPON_QTY,
  SPECIAL_SALES_AMT AS SPECIAL_SALES_AMT,
  SPECIAL_SALES_QTY AS SPECIAL_SALES_QTY,
  SPECIAL_RETURN_AMT AS SPECIAL_RETURN_AMT,
  SPECIAL_RETURN_QTY AS SPECIAL_RETURN_QTY,
  SPECIAL_SRVC_AMT AS SPECIAL_SRVC_AMT,
  SPECIAL_SRVC_QTY AS SPECIAL_SRVC_QTY,
  MA_SALES_AMT AS MA_SALES_AMT,
  MA_SALES_QTY AS MA_SALES_QTY,
  MA_TRANS_AMT AS MA_TRANS_AMT,
  MA_TRANS_COST AS MA_TRANS_COST,
  MA_TRANS_QTY AS MA_TRANS_QTY,
  EXCH_RATE_PCT AS EXCH_RATE_PCT,
  UPDATE_DT AS UPDATE_DT,
  LOAD_DT AS LOAD_DT
FROM
  SALES_DAY_SKU_STORE_RPT"""

df_15 = spark.sql(query_15)

df_15.createOrReplaceTempView("Shortcut_to_SALES_DAY_SKU_STORE_RPT1_15")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_SALES_DAY_SKU_STORE_RPT11_16


query_16 = f"""SELECT
  DAY_DT AS DAY_DT,
  PRODUCT_ID AS PRODUCT_ID,
  LOCATION_ID AS LOCATION_ID,
  SALES_CUST_CAPTURE_CD AS SALES_CUST_CAPTURE_CD,
  WEEK_DT AS WEEK_DT,
  FISCAL_YR AS FISCAL_YR,
  SKU_NBR AS SKU_NBR,
  STORE_NBR AS STORE_NBR,
  OPT_SALES_TYPE_ID AS OPT_SALES_TYPE_ID,
  VENDOR_ID AS VENDOR_ID,
  PROMO_FLAG AS PROMO_FLAG,
  STATUS_ID AS STATUS_ID,
  BRAND_NAME AS BRAND_NAME,
  OWNBRAND_FLAG AS OWNBRAND_FLAG,
  SKU_VEND_TXN_CNT AS SKU_VEND_TXN_CNT,
  NET_SALES_AMT AS NET_SALES_AMT,
  NET_SALES_QTY AS NET_SALES_QTY,
  NET_MARGIN_AMT AS NET_MARGIN_AMT,
  SALES_AMT AS SALES_AMT,
  SALES_COST AS SALES_COST,
  SALES_QTY AS SALES_QTY,
  RETURN_AMT AS RETURN_AMT,
  RETURN_COST AS RETURN_COST,
  RETURN_QTY AS RETURN_QTY,
  CLEARANCE_AMT AS CLEARANCE_AMT,
  CLEARANCE_QTY AS CLEARANCE_QTY,
  CLEARANCE_RETURN_AMT AS CLEARANCE_RETURN_AMT,
  CLEARANCE_RETURN_QTY AS CLEARANCE_RETURN_QTY,
  DISCOUNT_AMT AS DISCOUNT_AMT,
  DISCOUNT_QTY AS DISCOUNT_QTY,
  DISCOUNT_RETURN_AMT AS DISCOUNT_RETURN_AMT,
  DISCOUNT_RETURN_QTY AS DISCOUNT_RETURN_QTY,
  POS_COUPON_AMT AS POS_COUPON_AMT,
  POS_COUPON_QTY AS POS_COUPON_QTY,
  SPECIAL_SALES_AMT AS SPECIAL_SALES_AMT,
  SPECIAL_SALES_QTY AS SPECIAL_SALES_QTY,
  SPECIAL_RETURN_AMT AS SPECIAL_RETURN_AMT,
  SPECIAL_RETURN_QTY AS SPECIAL_RETURN_QTY,
  SPECIAL_SRVC_AMT AS SPECIAL_SRVC_AMT,
  SPECIAL_SRVC_QTY AS SPECIAL_SRVC_QTY,
  MA_SALES_AMT AS MA_SALES_AMT,
  MA_SALES_QTY AS MA_SALES_QTY,
  MA_TRANS_AMT AS MA_TRANS_AMT,
  MA_TRANS_COST AS MA_TRANS_COST,
  MA_TRANS_QTY AS MA_TRANS_QTY,
  EXCH_RATE_PCT AS EXCH_RATE_PCT,
  UPDATE_DT AS UPDATE_DT,
  LOAD_DT AS LOAD_DT
FROM
  SALES_DAY_SKU_STORE_RPT"""

df_16 = spark.sql(query_16)

df_16.createOrReplaceTempView("Shortcut_to_SALES_DAY_SKU_STORE_RPT11_16")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_DAYS_17


query_17 = f"""SELECT
  DAY_DT AS DAY_DT,
  BUSINESS_DAY_FLAG AS BUSINESS_DAY_FLAG,
  HOLIDAY_FLAG AS HOLIDAY_FLAG,
  DAY_OF_WK_NAME AS DAY_OF_WK_NAME,
  DAY_OF_WK_NAME_ABBR AS DAY_OF_WK_NAME_ABBR,
  DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  CAL_DAY_OF_MO_NBR AS CAL_DAY_OF_MO_NBR,
  CAL_DAY_OF_YR_NBR AS CAL_DAY_OF_YR_NBR,
  CAL_WK AS CAL_WK,
  CAL_WK_NBR AS CAL_WK_NBR,
  CAL_MO AS CAL_MO,
  CAL_MO_NBR AS CAL_MO_NBR,
  CAL_MO_NAME AS CAL_MO_NAME,
  CAL_MO_NAME_ABBR AS CAL_MO_NAME_ABBR,
  CAL_QTR AS CAL_QTR,
  CAL_QTR_NBR AS CAL_QTR_NBR,
  CAL_HALF AS CAL_HALF,
  CAL_YR AS CAL_YR,
  FISCAL_DAY_OF_MO_NBR AS FISCAL_DAY_OF_MO_NBR,
  FISCAL_DAY_OF_YR_NBR AS FISCAL_DAY_OF_YR_NBR,
  FISCAL_WK AS FISCAL_WK,
  FISCAL_WK_NBR AS FISCAL_WK_NBR,
  FISCAL_MO AS FISCAL_MO,
  FISCAL_MO_NBR AS FISCAL_MO_NBR,
  FISCAL_MO_NAME AS FISCAL_MO_NAME,
  FISCAL_MO_NAME_ABBR AS FISCAL_MO_NAME_ABBR,
  FISCAL_QTR AS FISCAL_QTR,
  FISCAL_QTR_NBR AS FISCAL_QTR_NBR,
  FISCAL_HALF AS FISCAL_HALF,
  FISCAL_YR AS FISCAL_YR,
  LYR_WEEK_DT AS LYR_WEEK_DT,
  LWK_WEEK_DT AS LWK_WEEK_DT,
  WEEK_DT AS WEEK_DT,
  EST_TIME_CONV_AMT AS EST_TIME_CONV_AMT,
  EST_TIME_CONV_HRS AS EST_TIME_CONV_HRS,
  ES0_TIME_CONV_AMT AS ES0_TIME_CONV_AMT,
  ES0_TIME_CONV_HRS AS ES0_TIME_CONV_HRS,
  CST_TIME_CONV_AMT AS CST_TIME_CONV_AMT,
  CST_TIME_CONV_HRS AS CST_TIME_CONV_HRS,
  CS0_TIME_CONV_AMT AS CS0_TIME_CONV_AMT,
  CS0_TIME_CONV_HRS AS CS0_TIME_CONV_HRS,
  MST_TIME_CONV_AMT AS MST_TIME_CONV_AMT,
  MST_TIME_CONV_HRS AS MST_TIME_CONV_HRS,
  MS0_TIME_CONV_AMT AS MS0_TIME_CONV_AMT,
  MS0_TIME_CONV_HRS AS MS0_TIME_CONV_HRS,
  PST_TIME_CONV_AMT AS PST_TIME_CONV_AMT,
  PST_TIME_CONV_HRS AS PST_TIME_CONV_HRS
FROM
  DAYS"""

df_17 = spark.sql(query_17)

df_17.createOrReplaceTempView("Shortcut_to_DAYS_17")

# COMMAND ----------
# DBTITLE 1, SQ_TY_MISSING_DAYS_18


query_18 = f"""SELECT
  DISTINCT Shortcut_to_PS2_HTL_ETL_CONTROL_0.PS2_HTL_RUN_DT AS PS2_HTL_RUN_DT,
  Shortcut_to_DAYS_17.DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  Shortcut_to_DAYS_17.DAY_DT AS DAY_DT,
  TPS.LOCATION_ID AS LOCATION_ID,
  ODD.DAY_CAMP_CNT AS DAY_CAMP_CNT,
  ODD.DAY_CARE_CNT AS DAY_CARE_CNT,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_PS2_HTL_OCCUPANCY_DATA_DEFAULT_6 ODD,
  Shortcut_to_DAYS_17,
  Shortcut_to_PS2_HTL_ETL_CONTROL_0,
  SITE_PROFILE_RPT,
  (
    SELECT
      DISTINCT TP.LOCATION_ID
    FROM
      Shortcut_to_TP_SERVICE_SCHEDULE_11 TP,
      Shortcut_to_PS2_HTL_ETL_CONTROL_0 PC
    WHERE
      TP.ROOM_TYPE_ID IN (2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16)
      AND TP.FOLIO_STATUS_FLAG IN ('A', 'I')
      AND PC.PS2_HTL_PROCESS_ID = 1
      AND TP.DAY_DT < PC.PS2_HTL_RUN_DT
      AND TP.DAY_DT > PC.PS2_HTL_RUN_DT - 43
  ) TPS
WHERE
  Shortcut_to_DAYS_17.DAY_DT < Shortcut_to_PS2_HTL_ETL_CONTROL_0.PS2_HTL_RUN_DT
  AND Shortcut_to_DAYS_17.DAY_DT > Shortcut_to_PS2_HTL_ETL_CONTROL_0.PS2_HTL_RUN_DT - 43
  AND Shortcut_to_PS2_HTL_ETL_CONTROL_0.PS2_HTL_PROCESS_ID = 1
  AND TPS.LOCATION_ID = SITE_PROFILE_RPT.LOCATION_ID
  AND ODD.DAY_DT = Shortcut_to_DAYS_17.DAY_DT"""

df_18 = spark.sql(query_18)

df_18.createOrReplaceTempView("SQ_TY_MISSING_DAYS_18")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_DAYS1_19


query_19 = f"""SELECT
  DAY_DT AS DAY_DT,
  BUSINESS_DAY_FLAG AS BUSINESS_DAY_FLAG,
  HOLIDAY_FLAG AS HOLIDAY_FLAG,
  DAY_OF_WK_NAME AS DAY_OF_WK_NAME,
  DAY_OF_WK_NAME_ABBR AS DAY_OF_WK_NAME_ABBR,
  DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  CAL_DAY_OF_MO_NBR AS CAL_DAY_OF_MO_NBR,
  CAL_DAY_OF_YR_NBR AS CAL_DAY_OF_YR_NBR,
  CAL_WK AS CAL_WK,
  CAL_WK_NBR AS CAL_WK_NBR,
  CAL_MO AS CAL_MO,
  CAL_MO_NBR AS CAL_MO_NBR,
  CAL_MO_NAME AS CAL_MO_NAME,
  CAL_MO_NAME_ABBR AS CAL_MO_NAME_ABBR,
  CAL_QTR AS CAL_QTR,
  CAL_QTR_NBR AS CAL_QTR_NBR,
  CAL_HALF AS CAL_HALF,
  CAL_YR AS CAL_YR,
  FISCAL_DAY_OF_MO_NBR AS FISCAL_DAY_OF_MO_NBR,
  FISCAL_DAY_OF_YR_NBR AS FISCAL_DAY_OF_YR_NBR,
  FISCAL_WK AS FISCAL_WK,
  FISCAL_WK_NBR AS FISCAL_WK_NBR,
  FISCAL_MO AS FISCAL_MO,
  FISCAL_MO_NBR AS FISCAL_MO_NBR,
  FISCAL_MO_NAME AS FISCAL_MO_NAME,
  FISCAL_MO_NAME_ABBR AS FISCAL_MO_NAME_ABBR,
  FISCAL_QTR AS FISCAL_QTR,
  FISCAL_QTR_NBR AS FISCAL_QTR_NBR,
  FISCAL_HALF AS FISCAL_HALF,
  FISCAL_YR AS FISCAL_YR,
  LYR_WEEK_DT AS LYR_WEEK_DT,
  LWK_WEEK_DT AS LWK_WEEK_DT,
  WEEK_DT AS WEEK_DT,
  EST_TIME_CONV_AMT AS EST_TIME_CONV_AMT,
  EST_TIME_CONV_HRS AS EST_TIME_CONV_HRS,
  ES0_TIME_CONV_AMT AS ES0_TIME_CONV_AMT,
  ES0_TIME_CONV_HRS AS ES0_TIME_CONV_HRS,
  CST_TIME_CONV_AMT AS CST_TIME_CONV_AMT,
  CST_TIME_CONV_HRS AS CST_TIME_CONV_HRS,
  CS0_TIME_CONV_AMT AS CS0_TIME_CONV_AMT,
  CS0_TIME_CONV_HRS AS CS0_TIME_CONV_HRS,
  MST_TIME_CONV_AMT AS MST_TIME_CONV_AMT,
  MST_TIME_CONV_HRS AS MST_TIME_CONV_HRS,
  MS0_TIME_CONV_AMT AS MS0_TIME_CONV_AMT,
  MS0_TIME_CONV_HRS AS MS0_TIME_CONV_HRS,
  PST_TIME_CONV_AMT AS PST_TIME_CONV_AMT,
  PST_TIME_CONV_HRS AS PST_TIME_CONV_HRS
FROM
  DAYS"""

df_19 = spark.sql(query_19)

df_19.createOrReplaceTempView("Shortcut_to_DAYS1_19")

# COMMAND ----------
# DBTITLE 1, SQ_LY_MISSING_DAYS_20


query_20 = f"""SELECT
  DISTINCT Shortcut_to_PS2_HTL_ETL_CONTROL1_1.PS2_HTL_RUN_DT AS PS2_HTL_RUN_DT,
  Shortcut_to_DAYS1_19.DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  PS2_DAYS_TY_LY.DAY_DT AS DAY_DT,
  TPS.LOCATION_ID AS LOCATION_ID,
  ODD.DAY_CAMP_CNT AS DAY_CAMP_CNT,
  ODD.DAY_CARE_CNT AS DAY_CARE_CNT,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_PS2_HTL_OCCUPANCY_DATA_DEFAULT1_7 ODD,
  Shortcut_to_DAYS1_19,
  PS2_DAYS_TY_LY,
  Shortcut_to_PS2_HTL_ETL_CONTROL1_1,
  SITE_PROFILE_RPT,
  (
    SELECT
      DISTINCT TP.LOCATION_ID
    FROM
      Shortcut_to_TP_SERVICE_SCHEDULE1_12 TP,
      Shortcut_to_PS2_HTL_ETL_CONTROL1_1 PC
    WHERE
      TP.ROOM_TYPE_ID IN (2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16)
      AND TP.FOLIO_STATUS_FLAG IN ('A', 'I')
      AND PC.PS2_HTL_PROCESS_ID = 1
      AND TP.DAY_DT < PC.PS2_HTL_RUN_DT
      AND TP.DAY_DT > PC.PS2_HTL_RUN_DT - 43
  ) TPS
WHERE
  Shortcut_to_DAYS1_19.DAY_DT < Shortcut_to_PS2_HTL_ETL_CONTROL1_1.PS2_HTL_RUN_DT
  AND Shortcut_to_DAYS1_19.DAY_DT > Shortcut_to_PS2_HTL_ETL_CONTROL1_1.PS2_HTL_RUN_DT - 43
  AND Shortcut_to_PS2_HTL_ETL_CONTROL1_1.PS2_HTL_PROCESS_ID = 1
  AND TPS.LOCATION_ID = SITE_PROFILE_RPT.LOCATION_ID
  AND Shortcut_to_DAYS1_19.DAY_DT = PS2_DAYS_TY_LY.DAY_DT
  AND PS2_DAYS_TY_LY.TRANS_DAY_DT = ODD.DAY_DT
  AND PS2_DAYS_TY_LY.TY_LY_FLAG = 'LY'"""

df_20 = spark.sql(query_20)

df_20.createOrReplaceTempView("SQ_LY_MISSING_DAYS_20")

# COMMAND ----------
# DBTITLE 1, LY_Shortcut_To_DAYS11_21


query_21 = f"""SELECT
  DAY_DT AS DAY_DT,
  BUSINESS_DAY_FLAG AS BUSINESS_DAY_FLAG,
  HOLIDAY_FLAG AS HOLIDAY_FLAG,
  DAY_OF_WK_NAME AS DAY_OF_WK_NAME,
  DAY_OF_WK_NAME_ABBR AS DAY_OF_WK_NAME_ABBR,
  DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  CAL_DAY_OF_MO_NBR AS CAL_DAY_OF_MO_NBR,
  CAL_DAY_OF_YR_NBR AS CAL_DAY_OF_YR_NBR,
  CAL_WK AS CAL_WK,
  CAL_WK_NBR AS CAL_WK_NBR,
  CAL_MO AS CAL_MO,
  CAL_MO_NBR AS CAL_MO_NBR,
  CAL_MO_NAME AS CAL_MO_NAME,
  CAL_MO_NAME_ABBR AS CAL_MO_NAME_ABBR,
  CAL_QTR AS CAL_QTR,
  CAL_QTR_NBR AS CAL_QTR_NBR,
  CAL_HALF AS CAL_HALF,
  CAL_YR AS CAL_YR,
  FISCAL_DAY_OF_MO_NBR AS FISCAL_DAY_OF_MO_NBR,
  FISCAL_DAY_OF_YR_NBR AS FISCAL_DAY_OF_YR_NBR,
  FISCAL_WK AS FISCAL_WK,
  FISCAL_WK_NBR AS FISCAL_WK_NBR,
  FISCAL_MO AS FISCAL_MO,
  FISCAL_MO_NBR AS FISCAL_MO_NBR,
  FISCAL_MO_NAME AS FISCAL_MO_NAME,
  FISCAL_MO_NAME_ABBR AS FISCAL_MO_NAME_ABBR,
  FISCAL_QTR AS FISCAL_QTR,
  FISCAL_QTR_NBR AS FISCAL_QTR_NBR,
  FISCAL_HALF AS FISCAL_HALF,
  FISCAL_YR AS FISCAL_YR,
  LYR_WEEK_DT AS LYR_WEEK_DT,
  LWK_WEEK_DT AS LWK_WEEK_DT,
  WEEK_DT AS WEEK_DT,
  EST_TIME_CONV_AMT AS EST_TIME_CONV_AMT,
  EST_TIME_CONV_HRS AS EST_TIME_CONV_HRS,
  ES0_TIME_CONV_AMT AS ES0_TIME_CONV_AMT,
  ES0_TIME_CONV_HRS AS ES0_TIME_CONV_HRS,
  CST_TIME_CONV_AMT AS CST_TIME_CONV_AMT,
  CST_TIME_CONV_HRS AS CST_TIME_CONV_HRS,
  CS0_TIME_CONV_AMT AS CS0_TIME_CONV_AMT,
  CS0_TIME_CONV_HRS AS CS0_TIME_CONV_HRS,
  MST_TIME_CONV_AMT AS MST_TIME_CONV_AMT,
  MST_TIME_CONV_HRS AS MST_TIME_CONV_HRS,
  MS0_TIME_CONV_AMT AS MS0_TIME_CONV_AMT,
  MS0_TIME_CONV_HRS AS MS0_TIME_CONV_HRS,
  PST_TIME_CONV_AMT AS PST_TIME_CONV_AMT,
  PST_TIME_CONV_HRS AS PST_TIME_CONV_HRS
FROM
  DAYS"""

df_21 = spark.sql(query_21)

df_21.createOrReplaceTempView("LY_Shortcut_To_DAYS11_21")

# COMMAND ----------
# DBTITLE 1, LY_Shortcut_To_DAYS111_22


query_22 = f"""SELECT
  DAY_DT AS DAY_DT,
  BUSINESS_DAY_FLAG AS BUSINESS_DAY_FLAG,
  HOLIDAY_FLAG AS HOLIDAY_FLAG,
  DAY_OF_WK_NAME AS DAY_OF_WK_NAME,
  DAY_OF_WK_NAME_ABBR AS DAY_OF_WK_NAME_ABBR,
  DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  CAL_DAY_OF_MO_NBR AS CAL_DAY_OF_MO_NBR,
  CAL_DAY_OF_YR_NBR AS CAL_DAY_OF_YR_NBR,
  CAL_WK AS CAL_WK,
  CAL_WK_NBR AS CAL_WK_NBR,
  CAL_MO AS CAL_MO,
  CAL_MO_NBR AS CAL_MO_NBR,
  CAL_MO_NAME AS CAL_MO_NAME,
  CAL_MO_NAME_ABBR AS CAL_MO_NAME_ABBR,
  CAL_QTR AS CAL_QTR,
  CAL_QTR_NBR AS CAL_QTR_NBR,
  CAL_HALF AS CAL_HALF,
  CAL_YR AS CAL_YR,
  FISCAL_DAY_OF_MO_NBR AS FISCAL_DAY_OF_MO_NBR,
  FISCAL_DAY_OF_YR_NBR AS FISCAL_DAY_OF_YR_NBR,
  FISCAL_WK AS FISCAL_WK,
  FISCAL_WK_NBR AS FISCAL_WK_NBR,
  FISCAL_MO AS FISCAL_MO,
  FISCAL_MO_NBR AS FISCAL_MO_NBR,
  FISCAL_MO_NAME AS FISCAL_MO_NAME,
  FISCAL_MO_NAME_ABBR AS FISCAL_MO_NAME_ABBR,
  FISCAL_QTR AS FISCAL_QTR,
  FISCAL_QTR_NBR AS FISCAL_QTR_NBR,
  FISCAL_HALF AS FISCAL_HALF,
  FISCAL_YR AS FISCAL_YR,
  LYR_WEEK_DT AS LYR_WEEK_DT,
  LWK_WEEK_DT AS LWK_WEEK_DT,
  WEEK_DT AS WEEK_DT,
  EST_TIME_CONV_AMT AS EST_TIME_CONV_AMT,
  EST_TIME_CONV_HRS AS EST_TIME_CONV_HRS,
  ES0_TIME_CONV_AMT AS ES0_TIME_CONV_AMT,
  ES0_TIME_CONV_HRS AS ES0_TIME_CONV_HRS,
  CST_TIME_CONV_AMT AS CST_TIME_CONV_AMT,
  CST_TIME_CONV_HRS AS CST_TIME_CONV_HRS,
  CS0_TIME_CONV_AMT AS CS0_TIME_CONV_AMT,
  CS0_TIME_CONV_HRS AS CS0_TIME_CONV_HRS,
  MST_TIME_CONV_AMT AS MST_TIME_CONV_AMT,
  MST_TIME_CONV_HRS AS MST_TIME_CONV_HRS,
  MS0_TIME_CONV_AMT AS MS0_TIME_CONV_AMT,
  MS0_TIME_CONV_HRS AS MS0_TIME_CONV_HRS,
  PST_TIME_CONV_AMT AS PST_TIME_CONV_AMT,
  PST_TIME_CONV_HRS AS PST_TIME_CONV_HRS
FROM
  DAYS"""

df_22 = spark.sql(query_22)

df_22.createOrReplaceTempView("LY_Shortcut_To_DAYS111_22")

# COMMAND ----------
# DBTITLE 1, LY_Shortcut_To_DAYS1_23


query_23 = f"""SELECT
  DAY_DT AS DAY_DT,
  BUSINESS_DAY_FLAG AS BUSINESS_DAY_FLAG,
  HOLIDAY_FLAG AS HOLIDAY_FLAG,
  DAY_OF_WK_NAME AS DAY_OF_WK_NAME,
  DAY_OF_WK_NAME_ABBR AS DAY_OF_WK_NAME_ABBR,
  DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  CAL_DAY_OF_MO_NBR AS CAL_DAY_OF_MO_NBR,
  CAL_DAY_OF_YR_NBR AS CAL_DAY_OF_YR_NBR,
  CAL_WK AS CAL_WK,
  CAL_WK_NBR AS CAL_WK_NBR,
  CAL_MO AS CAL_MO,
  CAL_MO_NBR AS CAL_MO_NBR,
  CAL_MO_NAME AS CAL_MO_NAME,
  CAL_MO_NAME_ABBR AS CAL_MO_NAME_ABBR,
  CAL_QTR AS CAL_QTR,
  CAL_QTR_NBR AS CAL_QTR_NBR,
  CAL_HALF AS CAL_HALF,
  CAL_YR AS CAL_YR,
  FISCAL_DAY_OF_MO_NBR AS FISCAL_DAY_OF_MO_NBR,
  FISCAL_DAY_OF_YR_NBR AS FISCAL_DAY_OF_YR_NBR,
  FISCAL_WK AS FISCAL_WK,
  FISCAL_WK_NBR AS FISCAL_WK_NBR,
  FISCAL_MO AS FISCAL_MO,
  FISCAL_MO_NBR AS FISCAL_MO_NBR,
  FISCAL_MO_NAME AS FISCAL_MO_NAME,
  FISCAL_MO_NAME_ABBR AS FISCAL_MO_NAME_ABBR,
  FISCAL_QTR AS FISCAL_QTR,
  FISCAL_QTR_NBR AS FISCAL_QTR_NBR,
  FISCAL_HALF AS FISCAL_HALF,
  FISCAL_YR AS FISCAL_YR,
  LYR_WEEK_DT AS LYR_WEEK_DT,
  LWK_WEEK_DT AS LWK_WEEK_DT,
  WEEK_DT AS WEEK_DT,
  EST_TIME_CONV_AMT AS EST_TIME_CONV_AMT,
  EST_TIME_CONV_HRS AS EST_TIME_CONV_HRS,
  ES0_TIME_CONV_AMT AS ES0_TIME_CONV_AMT,
  ES0_TIME_CONV_HRS AS ES0_TIME_CONV_HRS,
  CST_TIME_CONV_AMT AS CST_TIME_CONV_AMT,
  CST_TIME_CONV_HRS AS CST_TIME_CONV_HRS,
  CS0_TIME_CONV_AMT AS CS0_TIME_CONV_AMT,
  CS0_TIME_CONV_HRS AS CS0_TIME_CONV_HRS,
  MST_TIME_CONV_AMT AS MST_TIME_CONV_AMT,
  MST_TIME_CONV_HRS AS MST_TIME_CONV_HRS,
  MS0_TIME_CONV_AMT AS MS0_TIME_CONV_AMT,
  MS0_TIME_CONV_HRS AS MS0_TIME_CONV_HRS,
  PST_TIME_CONV_AMT AS PST_TIME_CONV_AMT,
  PST_TIME_CONV_HRS AS PST_TIME_CONV_HRS
FROM
  DAYS"""

df_23 = spark.sql(query_23)

df_23.createOrReplaceTempView("LY_Shortcut_To_DAYS1_23")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_DAYS11_24


query_24 = f"""SELECT
  DAY_DT AS DAY_DT,
  BUSINESS_DAY_FLAG AS BUSINESS_DAY_FLAG,
  HOLIDAY_FLAG AS HOLIDAY_FLAG,
  DAY_OF_WK_NAME AS DAY_OF_WK_NAME,
  DAY_OF_WK_NAME_ABBR AS DAY_OF_WK_NAME_ABBR,
  DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  CAL_DAY_OF_MO_NBR AS CAL_DAY_OF_MO_NBR,
  CAL_DAY_OF_YR_NBR AS CAL_DAY_OF_YR_NBR,
  CAL_WK AS CAL_WK,
  CAL_WK_NBR AS CAL_WK_NBR,
  CAL_MO AS CAL_MO,
  CAL_MO_NBR AS CAL_MO_NBR,
  CAL_MO_NAME AS CAL_MO_NAME,
  CAL_MO_NAME_ABBR AS CAL_MO_NAME_ABBR,
  CAL_QTR AS CAL_QTR,
  CAL_QTR_NBR AS CAL_QTR_NBR,
  CAL_HALF AS CAL_HALF,
  CAL_YR AS CAL_YR,
  FISCAL_DAY_OF_MO_NBR AS FISCAL_DAY_OF_MO_NBR,
  FISCAL_DAY_OF_YR_NBR AS FISCAL_DAY_OF_YR_NBR,
  FISCAL_WK AS FISCAL_WK,
  FISCAL_WK_NBR AS FISCAL_WK_NBR,
  FISCAL_MO AS FISCAL_MO,
  FISCAL_MO_NBR AS FISCAL_MO_NBR,
  FISCAL_MO_NAME AS FISCAL_MO_NAME,
  FISCAL_MO_NAME_ABBR AS FISCAL_MO_NAME_ABBR,
  FISCAL_QTR AS FISCAL_QTR,
  FISCAL_QTR_NBR AS FISCAL_QTR_NBR,
  FISCAL_HALF AS FISCAL_HALF,
  FISCAL_YR AS FISCAL_YR,
  LYR_WEEK_DT AS LYR_WEEK_DT,
  LWK_WEEK_DT AS LWK_WEEK_DT,
  WEEK_DT AS WEEK_DT,
  EST_TIME_CONV_AMT AS EST_TIME_CONV_AMT,
  EST_TIME_CONV_HRS AS EST_TIME_CONV_HRS,
  ES0_TIME_CONV_AMT AS ES0_TIME_CONV_AMT,
  ES0_TIME_CONV_HRS AS ES0_TIME_CONV_HRS,
  CST_TIME_CONV_AMT AS CST_TIME_CONV_AMT,
  CST_TIME_CONV_HRS AS CST_TIME_CONV_HRS,
  CS0_TIME_CONV_AMT AS CS0_TIME_CONV_AMT,
  CS0_TIME_CONV_HRS AS CS0_TIME_CONV_HRS,
  MST_TIME_CONV_AMT AS MST_TIME_CONV_AMT,
  MST_TIME_CONV_HRS AS MST_TIME_CONV_HRS,
  MS0_TIME_CONV_AMT AS MS0_TIME_CONV_AMT,
  MS0_TIME_CONV_HRS AS MS0_TIME_CONV_HRS,
  PST_TIME_CONV_AMT AS PST_TIME_CONV_AMT,
  PST_TIME_CONV_HRS AS PST_TIME_CONV_HRS
FROM
  DAYS"""

df_24 = spark.sql(query_24)

df_24.createOrReplaceTempView("Shortcut_to_DAYS11_24")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_SKU_PROFILE11_25


query_25 = f"""SELECT
  PRODUCT_ID AS PRODUCT_ID,
  SKU_NBR AS SKU_NBR,
  SKU_TYPE AS SKU_TYPE,
  PRIMARY_UPC_ID AS PRIMARY_UPC_ID,
  STATUS_ID AS STATUS_ID,
  SUBS_HIST_FLAG AS SUBS_HIST_FLAG,
  SUBS_CURR_FLAG AS SUBS_CURR_FLAG,
  SKU_DESC AS SKU_DESC,
  ALT_DESC AS ALT_DESC,
  SAP_CATEGORY_ID AS SAP_CATEGORY_ID,
  SAP_CLASS_ID AS SAP_CLASS_ID,
  SAP_DEPT_ID AS SAP_DEPT_ID,
  SAP_DIVISION_ID AS SAP_DIVISION_ID,
  PRIMARY_VENDOR_ID AS PRIMARY_VENDOR_ID,
  PARENT_VENDOR_ID AS PARENT_VENDOR_ID,
  COUNTRY_CD AS COUNTRY_CD,
  IMPORT_FLAG AS IMPORT_FLAG,
  HTS_CODE_ID AS HTS_CODE_ID,
  CONTENTS AS CONTENTS,
  CONTENTS_UNITS AS CONTENTS_UNITS,
  WEIGHT_NET_AMT AS WEIGHT_NET_AMT,
  WEIGHT_UOM_CD AS WEIGHT_UOM_CD,
  SIZE_DESC AS SIZE_DESC,
  BUM_QTY AS BUM_QTY,
  UOM_CD AS UOM_CD,
  UNIT_NUMERATOR AS UNIT_NUMERATOR,
  UNIT_DENOMINATOR AS UNIT_DENOMINATOR,
  BUYER_ID AS BUYER_ID,
  PURCH_GROUP_ID AS PURCH_GROUP_ID,
  PURCH_COST_AMT AS PURCH_COST_AMT,
  NAT_PRICE_US_AMT AS NAT_PRICE_US_AMT,
  TAX_CLASS_ID AS TAX_CLASS_ID,
  VALUATION_CLASS_CD AS VALUATION_CLASS_CD,
  BRAND_CD AS BRAND_CD,
  BRAND_CLASSIFICATION_ID AS BRAND_CLASSIFICATION_ID,
  OWNBRAND_FLAG AS OWNBRAND_FLAG,
  STATELINE_FLAG AS STATELINE_FLAG,
  SIGN_TYPE_CD AS SIGN_TYPE_CD,
  OLD_ARTICLE_NBR AS OLD_ARTICLE_NBR,
  VENDOR_ARTICLE_NBR AS VENDOR_ARTICLE_NBR,
  INIT_MKDN_DT AS INIT_MKDN_DT,
  DISC_START_DT AS DISC_START_DT,
  ADD_DT AS ADD_DT,
  DELETE_DT AS DELETE_DT,
  UPDATE_DT AS UPDATE_DT,
  FIRST_SALE_DT AS FIRST_SALE_DT,
  LAST_SALE_DT AS LAST_SALE_DT,
  FIRST_INV_DT AS FIRST_INV_DT,
  LAST_INV_DT AS LAST_INV_DT,
  LOAD_DT AS LOAD_DT,
  BASE_NBR AS BASE_NBR,
  BP_COLOR_ID AS BP_COLOR_ID,
  BP_SIZE_ID AS BP_SIZE_ID,
  BP_BREED_ID AS BP_BREED_ID,
  BP_ITEM_CONCATENATED AS BP_ITEM_CONCATENATED,
  BP_AEROSOL_FLAG AS BP_AEROSOL_FLAG,
  BP_HAZMAT_FLAG AS BP_HAZMAT_FLAG,
  CANADIAN_HTS_CD AS CANADIAN_HTS_CD,
  NAT_PRICE_CA_AMT AS NAT_PRICE_CA_AMT,
  NAT_PRICE_PR_AMT AS NAT_PRICE_PR_AMT,
  RTV_DEPT_CD AS RTV_DEPT_CD,
  GL_ACCT_NBR AS GL_ACCT_NBR,
  ARTICLE_CATEGORY_ID AS ARTICLE_CATEGORY_ID,
  COMPONENT_FLAG AS COMPONENT_FLAG,
  ZDISCO_SCHED_TYPE_ID AS ZDISCO_SCHED_TYPE_ID,
  ZDISCO_MKDN_SCHED_ID AS ZDISCO_MKDN_SCHED_ID,
  ZDISCO_PID_DT AS ZDISCO_PID_DT,
  ZDISCO_START_DT AS ZDISCO_START_DT,
  ZDISCO_INIT_MKDN_DT AS ZDISCO_INIT_MKDN_DT,
  ZDISCO_DC_DT AS ZDISCO_DC_DT,
  ZDISCO_STR_DT AS ZDISCO_STR_DT,
  ZDISCO_STR_OWNRSHP_DT AS ZDISCO_STR_OWNRSHP_DT,
  ZDISCO_STR_WRT_OFF_DT AS ZDISCO_STR_WRT_OFF_DT
FROM
  SKU_PROFILE"""

df_25 = spark.sql(query_25)

df_25.createOrReplaceTempView("Shortcut_to_SKU_PROFILE11_25")

# COMMAND ----------
# DBTITLE 1, LY_SALES_DAY_SKU_STORE_RPT_26


query_26 = f"""SELECT
  Shortcut_to_PS2_DAYS_TY_LY_9.DAY_DT AS DAY_DT,
  Shortcut_to_SALES_DAY_SKU_STORE_RPT11_16.LOCATION_ID AS LOCATION_ID,
  LY_Shortcut_To_DAYS11_21.DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  Shortcut_to_SALES_DAY_SKU_STORE_RPT11_16.SALES_QTY AS SALES_QTY,
  Shortcut_to_SKU_PROFILE11_25.SAP_CLASS_ID AS SAP_CLASS_ID,
  LY_Shortcut_to_PS2_HTL_ETL_CONTROL11_3.PS2_HTL_RUN_DT AS PROCESS_DT,
  Shortcut_to_SKU_PROFILE11_25.SAP_CATEGORY_ID AS SAP_CATEGORY_ID,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_SALES_DAY_SKU_STORE_RPT11_16,
  Shortcut_to_SKU_PROFILE11_25,
  LY_Shortcut_To_DAYS11_21,
  LY_Shortcut_to_PS2_HTL_ETL_CONTROL11_3,
  Shortcut_to_PS2_DAYS_TY_LY_9
WHERE
  Shortcut_to_SALES_DAY_SKU_STORE_RPT11_16.PRODUCT_ID = Shortcut_to_SKU_PROFILE11_25.PRODUCT_ID
  AND Shortcut_to_SALES_DAY_SKU_STORE_RPT11_16.SKU_NBR = Shortcut_to_SKU_PROFILE11_25.SKU_NBR
  AND Shortcut_to_PS2_DAYS_TY_LY_9.TRANS_DAY_DT = Shortcut_to_SALES_DAY_SKU_STORE_RPT11_16.DAY_DT
  AND Shortcut_to_PS2_DAYS_TY_LY_9.TY_LY_FLAG = 'LY'
  AND LY_Shortcut_To_DAYS11_21.DAY_DT = Shortcut_to_PS2_DAYS_TY_LY_9.DAY_DT
  AND Shortcut_to_SKU_PROFILE11_25.SAP_CLASS_ID IN (4921, 4913, 822)
  AND LY_Shortcut_to_PS2_HTL_ETL_CONTROL11_3.PS2_HTL_PROCESS_ID = 1
  AND Shortcut_to_PS2_DAYS_TY_LY_9.DAY_DT < LY_Shortcut_to_PS2_HTL_ETL_CONTROL11_3.PS2_HTL_RUN_DT
  AND Shortcut_to_PS2_DAYS_TY_LY_9.DAY_DT > LY_Shortcut_to_PS2_HTL_ETL_CONTROL11_3.PS2_HTL_RUN_DT - 43
  AND Shortcut_to_SALES_DAY_SKU_STORE_RPT11_16.STORE_NBR IN (
    SELECT
      DISTINCT STORE_NBR
    FROM
      PS2_HTL_FORECAST_PRE
  )"""

df_26 = spark.sql(query_26)

df_26.createOrReplaceTempView("LY_SALES_DAY_SKU_STORE_RPT_26")

# COMMAND ----------
# DBTITLE 1, EXP_ForecastDay_LY_27


query_27 = f"""SELECT
  DAY_DT AS DAY_DT,
  LOCATION_ID AS LOCATION_ID,
  DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  SALES_QTY AS SALES_QTY,
  SAP_CLASS_ID AS SAP_CLASS_ID,
  trunc(
    ADD_TO_DATE(
      ADD_TO_DATE(
        ADD_TO_DATE(
          PROCESS_DT,
          'D',
          TO_INTEGER(TO_CHAR(PROCESS_DT, 'D')) * -1
        ),
        'D',
        DAY_OF_WK_NBR
      ),
      'D',
      15
    )
  ) AS FORECAST_DAY,
  SAP_CATEGORY_ID AS SAP_CATEGORY_ID,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  LY_SALES_DAY_SKU_STORE_RPT_26"""

df_27 = spark.sql(query_27)

df_27.createOrReplaceTempView("EXP_ForecastDay_LY_27")

# COMMAND ----------
# DBTITLE 1, AGG_CountOvernightGuests_LY_28


query_28 = f"""SELECT
  DAY_DT AS DAY_DT,
  LOCATION_ID AS LOCATION_ID,
  DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  FORECAST_DAY AS FORECAST_DAY,
  SAP_CATEGORY_ID AS SAP_CATEGORY_ID,
  SUM(IFF(IN(SAP_CLASS_ID, 4921, 822), SALES_QTY, 0)) AS DAY_CAMP,
  SUM(
    IFF(
      IN(SAP_CLASS_ID, 4913)
      OR IN(SAP_CATEGORY_ID, 822001),
      SALES_QTY,
      0
    )
  ) AS BACK_OF_HOUSE,
  last(Monotonically_Increasing_Id) AS Monotonically_Increasing_Id
FROM
  EXP_ForecastDay_LY_27
GROUP BY
  DAY_DT,
  LOCATION_ID,
  DAY_OF_WK_NBR,
  FORECAST_DAY"""

df_28 = spark.sql(query_28)

df_28.createOrReplaceTempView("AGG_CountOvernightGuests_LY_28")

# COMMAND ----------
# DBTITLE 1, JNR_LY_MISSING_DAY_29


query_29 = f"""SELECT
  DETAIL.PS2_HTL_RUN_DT AS PS2_HTL_RUN_DT,
  DETAIL.DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  DETAIL.DAY_DT AS DAY_DT,
  DETAIL.LOCATION_ID AS LOCATION_ID,
  DETAIL.DAY_CAMP_CNT AS DAY_CAMP_CNT,
  DETAIL.DAY_CARE_CNT AS DAY_CARE_CNT,
  MASTER.DAY_DT AS DAY_DT1,
  MASTER.LOCATION_ID AS LOCATION_ID1,
  MASTER.DAY_OF_WK_NBR AS DAY_OF_WK_NBR1,
  MASTER.FORECAST_DAY AS FORECAST_DAY,
  MASTER.DAY_CAMP AS DAY_CAMP,
  MASTER.BACK_OF_HOUSE AS DAY_CARE,
  DETAIL.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  AGG_CountOvernightGuests_LY_28 MASTER
  RIGHT JOIN SQ_LY_MISSING_DAYS_20 DETAIL ON MASTER.DAY_DT = DETAIL.DAY_DT
  AND MASTER.LOCATION_ID = DETAIL.LOCATION_ID"""

df_29 = spark.sql(query_29)

df_29.createOrReplaceTempView("JNR_LY_MISSING_DAY_29")

# COMMAND ----------
# DBTITLE 1, EXP_LY_30


query_30 = f"""SELECT
  IFF(ISNULL(DAY_DT1), DAY_DT, DAY_DT1) AS DAY_DT,
  IFF(ISNULL(LOCATION_ID1), LOCATION_ID, LOCATION_ID1) AS LOCATION_ID,
  IFF(
    ISNULL(FORECAST_DAY),
    trunc(
      ADD_TO_DATE(
        ADD_TO_DATE(
          ADD_TO_DATE(
            PS2_HTL_RUN_DT,
            'D',
            TO_INTEGER(TO_CHAR(PS2_HTL_RUN_DT, 'D')) * -1
          ),
          'D',
          DAY_OF_WK_NBR
        ),
        'D',
        15
      )
    ),
    FORECAST_DAY
  ) AS FORECAST_DAY,
  IFF(ISNULL(DAY_CAMP), DAY_CAMP_CNT, DAY_CAMP) AS LY_DAY_CAMP,
  IFF(ISNULL(DAY_CARE), DAY_CARE_CNT, DAY_CARE) AS LY_BACK_OF_HOUSE,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  JNR_LY_MISSING_DAY_29"""

df_30 = spark.sql(query_30)

df_30.createOrReplaceTempView("EXP_LY_30")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_SKU_PROFILE111_31


query_31 = f"""SELECT
  PRODUCT_ID AS PRODUCT_ID,
  SKU_NBR AS SKU_NBR,
  SKU_TYPE AS SKU_TYPE,
  PRIMARY_UPC_ID AS PRIMARY_UPC_ID,
  STATUS_ID AS STATUS_ID,
  SUBS_HIST_FLAG AS SUBS_HIST_FLAG,
  SUBS_CURR_FLAG AS SUBS_CURR_FLAG,
  SKU_DESC AS SKU_DESC,
  ALT_DESC AS ALT_DESC,
  SAP_CATEGORY_ID AS SAP_CATEGORY_ID,
  SAP_CLASS_ID AS SAP_CLASS_ID,
  SAP_DEPT_ID AS SAP_DEPT_ID,
  SAP_DIVISION_ID AS SAP_DIVISION_ID,
  PRIMARY_VENDOR_ID AS PRIMARY_VENDOR_ID,
  PARENT_VENDOR_ID AS PARENT_VENDOR_ID,
  COUNTRY_CD AS COUNTRY_CD,
  IMPORT_FLAG AS IMPORT_FLAG,
  HTS_CODE_ID AS HTS_CODE_ID,
  CONTENTS AS CONTENTS,
  CONTENTS_UNITS AS CONTENTS_UNITS,
  WEIGHT_NET_AMT AS WEIGHT_NET_AMT,
  WEIGHT_UOM_CD AS WEIGHT_UOM_CD,
  SIZE_DESC AS SIZE_DESC,
  BUM_QTY AS BUM_QTY,
  UOM_CD AS UOM_CD,
  UNIT_NUMERATOR AS UNIT_NUMERATOR,
  UNIT_DENOMINATOR AS UNIT_DENOMINATOR,
  BUYER_ID AS BUYER_ID,
  PURCH_GROUP_ID AS PURCH_GROUP_ID,
  PURCH_COST_AMT AS PURCH_COST_AMT,
  NAT_PRICE_US_AMT AS NAT_PRICE_US_AMT,
  TAX_CLASS_ID AS TAX_CLASS_ID,
  VALUATION_CLASS_CD AS VALUATION_CLASS_CD,
  BRAND_CD AS BRAND_CD,
  BRAND_CLASSIFICATION_ID AS BRAND_CLASSIFICATION_ID,
  OWNBRAND_FLAG AS OWNBRAND_FLAG,
  STATELINE_FLAG AS STATELINE_FLAG,
  SIGN_TYPE_CD AS SIGN_TYPE_CD,
  OLD_ARTICLE_NBR AS OLD_ARTICLE_NBR,
  VENDOR_ARTICLE_NBR AS VENDOR_ARTICLE_NBR,
  INIT_MKDN_DT AS INIT_MKDN_DT,
  DISC_START_DT AS DISC_START_DT,
  ADD_DT AS ADD_DT,
  DELETE_DT AS DELETE_DT,
  UPDATE_DT AS UPDATE_DT,
  FIRST_SALE_DT AS FIRST_SALE_DT,
  LAST_SALE_DT AS LAST_SALE_DT,
  FIRST_INV_DT AS FIRST_INV_DT,
  LAST_INV_DT AS LAST_INV_DT,
  LOAD_DT AS LOAD_DT,
  BASE_NBR AS BASE_NBR,
  BP_COLOR_ID AS BP_COLOR_ID,
  BP_SIZE_ID AS BP_SIZE_ID,
  BP_BREED_ID AS BP_BREED_ID,
  BP_ITEM_CONCATENATED AS BP_ITEM_CONCATENATED,
  BP_AEROSOL_FLAG AS BP_AEROSOL_FLAG,
  BP_HAZMAT_FLAG AS BP_HAZMAT_FLAG,
  CANADIAN_HTS_CD AS CANADIAN_HTS_CD,
  NAT_PRICE_CA_AMT AS NAT_PRICE_CA_AMT,
  NAT_PRICE_PR_AMT AS NAT_PRICE_PR_AMT,
  RTV_DEPT_CD AS RTV_DEPT_CD,
  GL_ACCT_NBR AS GL_ACCT_NBR,
  ARTICLE_CATEGORY_ID AS ARTICLE_CATEGORY_ID,
  COMPONENT_FLAG AS COMPONENT_FLAG,
  ZDISCO_SCHED_TYPE_ID AS ZDISCO_SCHED_TYPE_ID,
  ZDISCO_MKDN_SCHED_ID AS ZDISCO_MKDN_SCHED_ID,
  ZDISCO_PID_DT AS ZDISCO_PID_DT,
  ZDISCO_START_DT AS ZDISCO_START_DT,
  ZDISCO_INIT_MKDN_DT AS ZDISCO_INIT_MKDN_DT,
  ZDISCO_DC_DT AS ZDISCO_DC_DT,
  ZDISCO_STR_DT AS ZDISCO_STR_DT,
  ZDISCO_STR_OWNRSHP_DT AS ZDISCO_STR_OWNRSHP_DT,
  ZDISCO_STR_WRT_OFF_DT AS ZDISCO_STR_WRT_OFF_DT
FROM
  SKU_PROFILE"""

df_31 = spark.sql(query_31)

df_31.createOrReplaceTempView("Shortcut_to_SKU_PROFILE111_31")

# COMMAND ----------
# DBTITLE 1, TY_SALES_DAY_SKU_STORE_RPT_32


query_32 = f"""SELECT
  Shortcut_to_SALES_DAY_SKU_STORE_RPT111_14.DAY_DT AS DAY_DT,
  Shortcut_to_SALES_DAY_SKU_STORE_RPT111_14.LOCATION_ID AS LOCATION_ID,
  LY_Shortcut_To_DAYS111_22.DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  Shortcut_to_SALES_DAY_SKU_STORE_RPT111_14.SALES_QTY AS SALES_QTY,
  Shortcut_to_SKU_PROFILE111_31.SAP_CLASS_ID AS SAP_CLASS_ID,
  LY_Shortcut_to_PS2_HTL_ETL_CONTROL111_2.PS2_HTL_RUN_DT AS PROCESS_DT,
  Shortcut_to_SKU_PROFILE111_31.SAP_CATEGORY_ID AS SAP_CATEGORY_ID,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  LY_Shortcut_to_PS2_HTL_ETL_CONTROL111_2,
  LY_Shortcut_To_DAYS111_22,
  Shortcut_to_SALES_DAY_SKU_STORE_RPT111_14,
  Shortcut_to_SKU_PROFILE111_31
WHERE
  Shortcut_to_SALES_DAY_SKU_STORE_RPT111_14.PRODUCT_ID = Shortcut_to_SKU_PROFILE111_31.PRODUCT_ID
  AND Shortcut_to_SALES_DAY_SKU_STORE_RPT111_14.SKU_NBR = Shortcut_to_SKU_PROFILE111_31.SKU_NBR
  AND Shortcut_to_SALES_DAY_SKU_STORE_RPT111_14.DAY_DT = LY_Shortcut_To_DAYS111_22.DAY_DT
  AND Shortcut_to_SKU_PROFILE111_31.SAP_CLASS_ID IN (4921, 4913, 822)
  AND LY_Shortcut_to_PS2_HTL_ETL_CONTROL111_2.PS2_HTL_PROCESS_ID = 1
  AND Shortcut_to_SALES_DAY_SKU_STORE_RPT111_14.DAY_DT < LY_Shortcut_to_PS2_HTL_ETL_CONTROL111_2.PS2_HTL_RUN_DT
  AND Shortcut_to_SALES_DAY_SKU_STORE_RPT111_14.DAY_DT > LY_Shortcut_to_PS2_HTL_ETL_CONTROL111_2.PS2_HTL_RUN_DT - 43
  AND Shortcut_to_SALES_DAY_SKU_STORE_RPT111_14.STORE_NBR IN (
    SELECT
      DISTINCT STORE_NBR
    FROM
      PS2_HTL_FORECAST_PRE
  )"""

df_32 = spark.sql(query_32)

df_32.createOrReplaceTempView("TY_SALES_DAY_SKU_STORE_RPT_32")

# COMMAND ----------
# DBTITLE 1, EXP_ForecastDay_TY_33


query_33 = f"""SELECT
  DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  DAY_DT AS DAY_DT,
  LOCATION_ID AS LOCATION_ID,
  trunc(
    ADD_TO_DATE(
      ADD_TO_DATE(
        ADD_TO_DATE(
          PROCESS_DT,
          'D',
          TO_INTEGER(TO_CHAR(PROCESS_DT, 'D')) * -1
        ),
        'D',
        DAY_OF_WK_NBR
      ),
      'D',
      15
    )
  ) AS FORECAST_DAY,
  SALES_QTY AS SALES_QTY,
  SAP_CLASS_ID AS SAP_CLASS_ID,
  SAP_CATEGORY_ID AS SAP_CATEGORY_ID,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  TY_SALES_DAY_SKU_STORE_RPT_32"""

df_33 = spark.sql(query_33)

df_33.createOrReplaceTempView("EXP_ForecastDay_TY_33")

# COMMAND ----------
# DBTITLE 1, AGG_CountOvernightGuests_TY_34


query_34 = f"""SELECT
  DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  DAY_DT AS DAY_DT,
  LOCATION_ID AS LOCATION_ID,
  FORECAST_DAY AS FORECAST_DAY,
  SAP_CATEGORY_ID AS SAP_CATEGORY_ID,
  SUM(IFF(IN(SAP_CLASS_ID, 4921, 822), SALES_QTY, 0)) AS DAY_CAMP,
  SUM(
    IFF(
      IN(SAP_CLASS_ID, 4913)
      OR IN(SAP_CATEGORY_ID, 822001),
      SALES_QTY,
      0
    )
  ) AS DAY_CARE,
  last(Monotonically_Increasing_Id) AS Monotonically_Increasing_Id
FROM
  EXP_ForecastDay_TY_33
GROUP BY
  DAY_OF_WK_NBR,
  DAY_DT,
  LOCATION_ID,
  FORECAST_DAY"""

df_34 = spark.sql(query_34)

df_34.createOrReplaceTempView("AGG_CountOvernightGuests_TY_34")

# COMMAND ----------
# DBTITLE 1, JNR_TY_MISSING_DAY_35


query_35 = f"""SELECT
  DETAIL.PS2_HTL_RUN_DT AS PS2_HTL_RUN_DT,
  DETAIL.DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  DETAIL.DAY_DT AS DAY_DT,
  DETAIL.LOCATION_ID AS LOCATION_ID,
  DETAIL.DAY_CAMP_CNT AS DAY_CAMP_CNT,
  DETAIL.DAY_CARE_CNT AS DAY_CARE_CNT,
  MASTER.DAY_OF_WK_NBR AS DAY_OF_WK_NBR1,
  MASTER.DAY_DT AS DAY_DT1,
  MASTER.LOCATION_ID AS LOCATION_ID1,
  MASTER.FORECAST_DAY AS FORECAST_DAY,
  MASTER.DAY_CAMP AS DAY_CAMP,
  MASTER.DAY_CARE AS DAY_CARE,
  DETAIL.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  AGG_CountOvernightGuests_TY_34 MASTER
  RIGHT JOIN SQ_TY_MISSING_DAYS_18 DETAIL ON MASTER.DAY_DT = DETAIL.DAY_DT
  AND MASTER.LOCATION_ID = DETAIL.LOCATION_ID"""

df_35 = spark.sql(query_35)

df_35.createOrReplaceTempView("JNR_TY_MISSING_DAY_35")

# COMMAND ----------
# DBTITLE 1, EXP_TY_36


query_36 = f"""SELECT
  IFF(
    ISNULL(DAY_OF_WK_NBR1),
    DAY_OF_WK_NBR,
    DAY_OF_WK_NBR1
  ) AS DAY_OF_WK_NBR,
  IFF(ISNULL(DAY_DT1), DAY_DT, DAY_DT1) AS DAY_DT,
  IFF(ISNULL(LOCATION_ID1), LOCATION_ID, LOCATION_ID1) AS LOCATION_ID,
  IFF(
    ISNULL(FORECAST_DAY),
    trunc(
      ADD_TO_DATE(
        ADD_TO_DATE(
          ADD_TO_DATE(
            PS2_HTL_RUN_DT,
            'D',
            TO_INTEGER(TO_CHAR(PS2_HTL_RUN_DT, 'D')) * -1
          ),
          'D',
          DAY_OF_WK_NBR
        ),
        'D',
        15
      )
    ),
    FORECAST_DAY
  ) AS FORECAST_DAY,
  IFF(ISNULL(DAY_CAMP), DAY_CAMP_CNT, DAY_CAMP) AS TY_DAY_CAMP,
  IFF(ISNULL(DAY_CARE), DAY_CARE_CNT, DAY_CARE) AS TY_BACK_OF_HOUSE,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  JNR_TY_MISSING_DAY_35"""

df_36 = spark.sql(query_36)

df_36.createOrReplaceTempView("EXP_TY_36")

# COMMAND ----------
# DBTITLE 1, JNR_OVERNIGHT_GUEST_37


query_37 = f"""SELECT
  DETAIL.DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  DETAIL.DAY_DT AS DAY_DT,
  DETAIL.LOCATION_ID AS LOCATION_ID,
  DETAIL.FORECAST_DAY AS FORECAST_DAY,
  DETAIL.TY_DAY_CAMP AS TY_DAY_CAMP,
  DETAIL.TY_BACK_OF_HOUSE AS TY_BACK_OF_HOUSE,
  MASTER.DAY_DT AS LY_DAY_DT,
  MASTER.LOCATION_ID AS LY_LOCATION_ID,
  MASTER.FORECAST_DAY AS LY_FORECAST_DAY,
  MASTER.LY_DAY_CAMP AS LY_DAY_CAMP,
  MASTER.LY_BACK_OF_HOUSE AS LY_BACK_OF_HOUSE,
  MASTER.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  EXP_LY_30 MASTER
  INNER JOIN EXP_TY_36 DETAIL ON MASTER.DAY_DT = DETAIL.DAY_DT
  AND MASTER.LOCATION_ID = DETAIL.LOCATION_ID
  AND MASTER.FORECAST_DAY = DETAIL.FORECAST_DAY"""

df_37 = spark.sql(query_37)

df_37.createOrReplaceTempView("JNR_OVERNIGHT_GUEST_37")

# COMMAND ----------
# DBTITLE 1, UPD_PS2_HTL_FORECAST_TY_LY_TOTAL_PRE_38


query_38 = f"""SELECT
  FORECAST_DAY AS FORECAST_DAY,
  DAY_DT AS DAY_DT,
  LOCATION_ID AS LOCATION_ID,
  TY_DAY_CAMP AS TY_DAY_CAMP_PLAYROOM,
  LY_DAY_CAMP AS LY_DAY_CAMP_PLAYROOM,
  TY_BACK_OF_HOUSE AS TY_DAY_CARE,
  LY_BACK_OF_HOUSE AS LY_DAY_CARE,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  JNR_OVERNIGHT_GUEST_37"""

df_38 = spark.sql(query_38)

df_38.createOrReplaceTempView("UPD_PS2_HTL_FORECAST_TY_LY_TOTAL_PRE_38")

# COMMAND ----------
# DBTITLE 1, LKP_DAYS_NBR_39


query_39 = f"""SELECT
  D.DAY_DT AS DAY_DT,
  D.WEEK_DT AS WEEK_DT,
  JOG3.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  JNR_OVERNIGHT_GUEST_37 JOG3
  LEFT JOIN DAYS D ON D.DAY_DT = JOG3.DAY_DT"""

df_39 = spark.sql(query_39)

df_39.createOrReplaceTempView("LKP_DAYS_NBR_39")

# COMMAND ----------
# DBTITLE 1, SRT_WEEK_40


query_40 = f"""SELECT
  JOG3.DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  JOG3.LOCATION_ID AS LOCATION_ID,
  LDN3.WEEK_DT AS WEEK_DT,
  LDN3.DAY_DT AS DAY_DT,
  JOG3.FORECAST_DAY AS FORECAST_DAY,
  JOG3.TY_DAY_CAMP AS TY_DAY_CAMP,
  JOG3.TY_BACK_OF_HOUSE AS TY_BACK_OF_HOUSE,
  JOG3.LY_DAY_CAMP AS LY_DAY_CAMP,
  JOG3.LY_BACK_OF_HOUSE AS LY_BACK_OF_HOUSE,
  LDN3.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  LKP_DAYS_NBR_39 LDN3
  INNER JOIN JNR_OVERNIGHT_GUEST_37 JOG3 ON LDN3.Monotonically_Increasing_Id = JOG3.Monotonically_Increasing_Id
ORDER BY
  LOCATION_ID ASC,
  WEEK_DT DESC,
  DAY_DT DESC"""

df_40 = spark.sql(query_40)

df_40.createOrReplaceTempView("SRT_WEEK_40")

# COMMAND ----------
# DBTITLE 1, EXP_WEEK_NBR_41


query_41 = f"""SELECT
  DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  LOCATION_ID AS LOCATION_ID,
  FORECAST_DAY AS FORECAST_DAY,
  TY_DAY_CAMP AS TY_DAY_CAMP,
  TY_BACK_OF_HOUSE AS TY_BACK_OF_HOUSE,
  LY_DAY_CAMP AS LY_DAY_CAMP,
  LY_BACK_OF_HOUSE AS LY_BACK_OF_HOUSE,
  IFF(v_COUNT = 42, 1, v_COUNT + 1) AS v_COUNT,
  1 AS LIMIT_HIGH_ID,
  2 AS LIMIT_LOW_ID,
  IFF(
    IFF(v_COUNT = 42, 1, v_COUNT + 1) >= 1
    AND IFF(v_COUNT = 42, 1, v_COUNT + 1) <= 7,
    1,
    IFF(
      IFF(v_COUNT = 42, 1, v_COUNT + 1) >= 8
      AND IFF(v_COUNT = 42, 1, v_COUNT + 1) <= 14,
      2,
      IFF(
        IFF(v_COUNT = 42, 1, v_COUNT + 1) >= 15
        AND IFF(v_COUNT = 42, 1, v_COUNT + 1) <= 21,
        3,
        IFF(
          IFF(v_COUNT = 42, 1, v_COUNT + 1) >= 22
          AND IFF(v_COUNT = 42, 1, v_COUNT + 1) <= 28,
          4,
          IFF(
            IFF(v_COUNT = 42, 1, v_COUNT + 1) >= 29
            AND IFF(v_COUNT = 42, 1, v_COUNT + 1) <= 35,
            5,
            IFF(
              IFF(v_COUNT = 42, 1, v_COUNT + 1) >= 36
              AND IFF(v_COUNT = 42, 1, v_COUNT + 1) <= 42,
              6,
              0
            )
          )
        )
      )
    )
  ) AS WEEK_NBR,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  SRT_WEEK_40"""

df_41 = spark.sql(query_41)

df_41.createOrReplaceTempView("EXP_WEEK_NBR_41")

# COMMAND ----------
# DBTITLE 1, LKP_PS2_HTL_LIMITS_HIGH_42


query_42 = f"""SELECT
  PHL.LIMIT_QTY AS LIMIT_QTY,
  EWN4.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  EXP_WEEK_NBR_41 EWN4
  LEFT JOIN PS2_HTL_LIMITS PHL ON PHL.LIMIT_ID = EWN4.LIMIT_HIGH_ID"""

df_42 = spark.sql(query_42)

df_42.createOrReplaceTempView("LKP_PS2_HTL_LIMITS_HIGH_42")

# COMMAND ----------
# DBTITLE 1, LKP_PS2_HTL_LIMITS_LOW_43


query_43 = f"""SELECT
  PHL.LIMIT_QTY AS LIMIT_QTY,
  EWN4.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  EXP_WEEK_NBR_41 EWN4
  LEFT JOIN PS2_HTL_LIMITS PHL ON PHL.LIMIT_ID = EWN4.LIMIT_LOW_ID"""

df_43 = spark.sql(query_43)

df_43.createOrReplaceTempView("LKP_PS2_HTL_LIMITS_LOW_43")

# COMMAND ----------
# DBTITLE 1, LKP_DAYS_44


query_44 = f"""SELECT
  D.WEEK_DT AS WEEK_DT,
  EWN4.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  EXP_WEEK_NBR_41 EWN4
  LEFT JOIN DAYS D ON D.DAY_DT = EWN4.FORECAST_DAY"""

df_44 = spark.sql(query_44)

df_44.createOrReplaceTempView("LKP_DAYS_44")

# COMMAND ----------
# DBTITLE 1, EXP_Limits_45


query_45 = f"""SELECT
  EWN4.FORECAST_DAY AS FORECAST_DAY,
  EWN4.LOCATION_ID AS LOCATION_ID,
  LD4.WEEK_DT AS WEEK_DT,
  EWN4.DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  IFF(ISNULL(i_TY_DAY_CAMP), 0, i_TY_DAY_CAMP) AS TY_DAY_CAMP,
  IFF(ISNULL(i_TY_BACK_OF_HOUSE), 0, i_TY_BACK_OF_HOUSE) AS TY_BACK_OF_HOUSE,
  IFF(ISNULL(i_LY_DAY_CAMP), 0, i_LY_DAY_CAMP) AS LY_DAY_CAMP,
  IFF(ISNULL(i_LY_BACK_OF_HOUSE), 0, i_LY_BACK_OF_HOUSE) AS LY_BACK_OF_HOUSE,
  EWN4.WEEK_NBR AS WEEK_NBR,
  ROUND(
    IFF (
      IFF(
        IFF(ISNULL(EWN4.LY_DAY_CAMP), 0, EWN4.LY_DAY_CAMP) <> 0.00,
        IFF(ISNULL(EWN4.TY_DAY_CAMP), 0, EWN4.TY_DAY_CAMP) / IFF(ISNULL(EWN4.LY_DAY_CAMP), 0, EWN4.LY_DAY_CAMP) -1,
        0.00
      ) > LPHLH4.LIMIT_QTY,
      LPHLH4.LIMIT_QTY,
      IFF (
        IFF(
          IFF(ISNULL(EWN4.LY_DAY_CAMP), 0, EWN4.LY_DAY_CAMP) <> 0.00,
          IFF(ISNULL(EWN4.TY_DAY_CAMP), 0, EWN4.TY_DAY_CAMP) / IFF(ISNULL(EWN4.LY_DAY_CAMP), 0, EWN4.LY_DAY_CAMP) -1,
          0.00
        ) < LPHLL4.LIMIT_QTY,
        LPHLL4.LIMIT_QTY,
        IFF(
          IFF(ISNULL(EWN4.LY_DAY_CAMP), 0, EWN4.LY_DAY_CAMP) <> 0.00,
          IFF(ISNULL(EWN4.TY_DAY_CAMP), 0, EWN4.TY_DAY_CAMP) / IFF(ISNULL(EWN4.LY_DAY_CAMP), 0, EWN4.LY_DAY_CAMP) -1,
          0.00
        )
      )
    ),
    5
  ) AS DAY_CAMP_CNT,
  ROUND(
    IFF (
      IFF(
        IFF(
          ISNULL(EWN4.LY_BACK_OF_HOUSE),
          0,
          EWN4.LY_BACK_OF_HOUSE
        ) <> 0.00,
        IFF(
          ISNULL(EWN4.TY_BACK_OF_HOUSE),
          0,
          EWN4.TY_BACK_OF_HOUSE
        ) / IFF(
          ISNULL(EWN4.LY_BACK_OF_HOUSE),
          0,
          EWN4.LY_BACK_OF_HOUSE
        ) -1,
        0.00
      ) > 0.50,
      0.50,
      IFF (
        IFF(
          IFF(
            ISNULL(EWN4.LY_BACK_OF_HOUSE),
            0,
            EWN4.LY_BACK_OF_HOUSE
          ) <> 0.00,
          IFF(
            ISNULL(EWN4.TY_BACK_OF_HOUSE),
            0,
            EWN4.TY_BACK_OF_HOUSE
          ) / IFF(
            ISNULL(EWN4.LY_BACK_OF_HOUSE),
            0,
            EWN4.LY_BACK_OF_HOUSE
          ) -1,
          0.00
        ) < - 0.50,
        - 0.50,
        IFF(
          IFF(
            ISNULL(EWN4.LY_BACK_OF_HOUSE),
            0,
            EWN4.LY_BACK_OF_HOUSE
          ) <> 0.00,
          IFF(
            ISNULL(EWN4.TY_BACK_OF_HOUSE),
            0,
            EWN4.TY_BACK_OF_HOUSE
          ) / IFF(
            ISNULL(EWN4.LY_BACK_OF_HOUSE),
            0,
            EWN4.LY_BACK_OF_HOUSE
          ) -1,
          0.00
        )
      )
    ),
    5
  ) AS BACK_OF_HOUSE_CNT,
  LD4.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  LKP_DAYS_44 LD4
  INNER JOIN EXP_WEEK_NBR_41 EWN4 ON LD4.Monotonically_Increasing_Id = EWN4.Monotonically_Increasing_Id
  INNER JOIN LKP_PS2_HTL_LIMITS_HIGH_42 LPHLH4 ON EWN4.Monotonically_Increasing_Id = LPHLH4.Monotonically_Increasing_Id
  INNER JOIN LKP_PS2_HTL_LIMITS_LOW_43 LPHLL4 ON LPHLH4.Monotonically_Increasing_Id = LPHLL4.Monotonically_Increasing_Id"""

df_45 = spark.sql(query_45)

df_45.createOrReplaceTempView("EXP_Limits_45")

# COMMAND ----------
# DBTITLE 1, LKP_PS2_HTL_WEIGHT_46


query_46 = f"""SELECT
  PHW.WEIGHT_QTY AS WEIGHT_QTY,
  EL4.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  EXP_Limits_45 EL4
  LEFT JOIN PS2_HTL_WEIGHT PHW ON PHW.WEEK_NBR = EL4.WEEK_NBR"""

df_46 = spark.sql(query_46)

df_46.createOrReplaceTempView("LKP_PS2_HTL_WEIGHT_46")

# COMMAND ----------
# DBTITLE 1, AGG_Weight_47


query_47 = f"""SELECT
  EL4.FORECAST_DAY AS FORECAST_DAY,
  EL4.LOCATION_ID AS LOCATION_ID,
  EL4.WEEK_DT AS WEEK_DT,
  EL4.DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  ROUND(SUM(EL4.DAY_CAMP_CNT * LPHW4.WEIGHT_QTY), 5) AS DAY_CAMP_CNT,
  ROUND(SUM(EL4.BACK_OF_HOUSE_CNT * LPHW4.WEIGHT_QTY), 5) AS BACK_OF_HOUSE_CNT,
  last(LPHW4.Monotonically_Increasing_Id) AS Monotonically_Increasing_Id
FROM
  LKP_PS2_HTL_WEIGHT_46 LPHW4
  INNER JOIN EXP_Limits_45 EL4 ON LPHW4.Monotonically_Increasing_Id = EL4.Monotonically_Increasing_Id
GROUP BY
  FORECAST_DAY,
  LOCATION_ID,
  WEEK_DT,
  DAY_OF_WK_NBR"""

df_47 = spark.sql(query_47)

df_47.createOrReplaceTempView("AGG_Weight_47")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_SKU_PROFILE1_48


query_48 = f"""SELECT
  PRODUCT_ID AS PRODUCT_ID,
  SKU_NBR AS SKU_NBR,
  SKU_TYPE AS SKU_TYPE,
  PRIMARY_UPC_ID AS PRIMARY_UPC_ID,
  STATUS_ID AS STATUS_ID,
  SUBS_HIST_FLAG AS SUBS_HIST_FLAG,
  SUBS_CURR_FLAG AS SUBS_CURR_FLAG,
  SKU_DESC AS SKU_DESC,
  ALT_DESC AS ALT_DESC,
  SAP_CATEGORY_ID AS SAP_CATEGORY_ID,
  SAP_CLASS_ID AS SAP_CLASS_ID,
  SAP_DEPT_ID AS SAP_DEPT_ID,
  SAP_DIVISION_ID AS SAP_DIVISION_ID,
  PRIMARY_VENDOR_ID AS PRIMARY_VENDOR_ID,
  PARENT_VENDOR_ID AS PARENT_VENDOR_ID,
  COUNTRY_CD AS COUNTRY_CD,
  IMPORT_FLAG AS IMPORT_FLAG,
  HTS_CODE_ID AS HTS_CODE_ID,
  CONTENTS AS CONTENTS,
  CONTENTS_UNITS AS CONTENTS_UNITS,
  WEIGHT_NET_AMT AS WEIGHT_NET_AMT,
  WEIGHT_UOM_CD AS WEIGHT_UOM_CD,
  SIZE_DESC AS SIZE_DESC,
  BUM_QTY AS BUM_QTY,
  UOM_CD AS UOM_CD,
  UNIT_NUMERATOR AS UNIT_NUMERATOR,
  UNIT_DENOMINATOR AS UNIT_DENOMINATOR,
  BUYER_ID AS BUYER_ID,
  PURCH_GROUP_ID AS PURCH_GROUP_ID,
  PURCH_COST_AMT AS PURCH_COST_AMT,
  NAT_PRICE_US_AMT AS NAT_PRICE_US_AMT,
  TAX_CLASS_ID AS TAX_CLASS_ID,
  VALUATION_CLASS_CD AS VALUATION_CLASS_CD,
  BRAND_CD AS BRAND_CD,
  BRAND_CLASSIFICATION_ID AS BRAND_CLASSIFICATION_ID,
  OWNBRAND_FLAG AS OWNBRAND_FLAG,
  STATELINE_FLAG AS STATELINE_FLAG,
  SIGN_TYPE_CD AS SIGN_TYPE_CD,
  OLD_ARTICLE_NBR AS OLD_ARTICLE_NBR,
  VENDOR_ARTICLE_NBR AS VENDOR_ARTICLE_NBR,
  INIT_MKDN_DT AS INIT_MKDN_DT,
  DISC_START_DT AS DISC_START_DT,
  ADD_DT AS ADD_DT,
  DELETE_DT AS DELETE_DT,
  UPDATE_DT AS UPDATE_DT,
  FIRST_SALE_DT AS FIRST_SALE_DT,
  LAST_SALE_DT AS LAST_SALE_DT,
  FIRST_INV_DT AS FIRST_INV_DT,
  LAST_INV_DT AS LAST_INV_DT,
  LOAD_DT AS LOAD_DT,
  BASE_NBR AS BASE_NBR,
  BP_COLOR_ID AS BP_COLOR_ID,
  BP_SIZE_ID AS BP_SIZE_ID,
  BP_BREED_ID AS BP_BREED_ID,
  BP_ITEM_CONCATENATED AS BP_ITEM_CONCATENATED,
  BP_AEROSOL_FLAG AS BP_AEROSOL_FLAG,
  BP_HAZMAT_FLAG AS BP_HAZMAT_FLAG,
  CANADIAN_HTS_CD AS CANADIAN_HTS_CD,
  NAT_PRICE_CA_AMT AS NAT_PRICE_CA_AMT,
  NAT_PRICE_PR_AMT AS NAT_PRICE_PR_AMT,
  RTV_DEPT_CD AS RTV_DEPT_CD,
  GL_ACCT_NBR AS GL_ACCT_NBR,
  ARTICLE_CATEGORY_ID AS ARTICLE_CATEGORY_ID,
  COMPONENT_FLAG AS COMPONENT_FLAG,
  ZDISCO_SCHED_TYPE_ID AS ZDISCO_SCHED_TYPE_ID,
  ZDISCO_MKDN_SCHED_ID AS ZDISCO_MKDN_SCHED_ID,
  ZDISCO_PID_DT AS ZDISCO_PID_DT,
  ZDISCO_START_DT AS ZDISCO_START_DT,
  ZDISCO_INIT_MKDN_DT AS ZDISCO_INIT_MKDN_DT,
  ZDISCO_DC_DT AS ZDISCO_DC_DT,
  ZDISCO_STR_DT AS ZDISCO_STR_DT,
  ZDISCO_STR_OWNRSHP_DT AS ZDISCO_STR_OWNRSHP_DT,
  ZDISCO_STR_WRT_OFF_DT AS ZDISCO_STR_WRT_OFF_DT
FROM
  SKU_PROFILE"""

df_48 = spark.sql(query_48)

df_48.createOrReplaceTempView("Shortcut_to_SKU_PROFILE1_48")

# COMMAND ----------
# DBTITLE 1, LY_SW_SALES_DAY_SKU_STORE_RPT_49


query_49 = f"""SELECT
  Shortcut_to_PS2_DAYS_TY_LY1_10.DAY_DT AS DAY_DT,
  Shortcut_to_SALES_DAY_SKU_STORE_RPT1_15.LOCATION_ID AS LOCATION_ID,
  LY_Shortcut_To_DAYS1_23.DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  Shortcut_to_SALES_DAY_SKU_STORE_RPT1_15.SALES_QTY AS SALES_QTY,
  Shortcut_to_SKU_PROFILE1_48.SAP_CLASS_ID AS SAP_CLASS_ID,
  LY_Shortcut_to_PS2_HTL_ETL_CONTROL1_4.PS2_HTL_RUN_DT AS PROCESS_DT,
  Shortcut_to_SKU_PROFILE1_48.SAP_CATEGORY_ID AS SAP_CATEGORY_ID,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  LY_Shortcut_to_PS2_HTL_ETL_CONTROL1_4,
  LY_Shortcut_To_DAYS1_23,
  Shortcut_to_PS2_DAYS_TY_LY1_10,
  Shortcut_to_SALES_DAY_SKU_STORE_RPT1_15,
  Shortcut_to_SKU_PROFILE1_48
WHERE
  Shortcut_to_SALES_DAY_SKU_STORE_RPT1_15.PRODUCT_ID = Shortcut_to_SKU_PROFILE1_48.PRODUCT_ID
  AND Shortcut_to_SALES_DAY_SKU_STORE_RPT1_15.SKU_NBR = Shortcut_to_SKU_PROFILE1_48.SKU_NBR
  AND Shortcut_to_PS2_DAYS_TY_LY1_10.TRANS_DAY_DT = Shortcut_to_SALES_DAY_SKU_STORE_RPT1_15.DAY_DT
  AND Shortcut_to_PS2_DAYS_TY_LY1_10.TY_LY_FLAG = 'LY'
  AND LY_Shortcut_To_DAYS1_23.DAY_DT = Shortcut_to_PS2_DAYS_TY_LY1_10.DAY_DT
  AND Shortcut_to_SKU_PROFILE1_48.SAP_CLASS_ID IN (4921, 4913, 822)
  AND LY_Shortcut_to_PS2_HTL_ETL_CONTROL1_4.PS2_HTL_PROCESS_ID = 1
  AND Shortcut_to_PS2_DAYS_TY_LY1_10.DAY_DT < LY_Shortcut_to_PS2_HTL_ETL_CONTROL1_4.PS2_HTL_RUN_DT + 21
  AND Shortcut_to_PS2_DAYS_TY_LY1_10.DAY_DT > LY_Shortcut_to_PS2_HTL_ETL_CONTROL1_4.PS2_HTL_RUN_DT + 13
  AND Shortcut_to_SALES_DAY_SKU_STORE_RPT1_15.STORE_NBR IN (
    SELECT
      DISTINCT STORE_NBR
    FROM
      PS2_HTL_FORECAST_PRE
  )"""

df_49 = spark.sql(query_49)

df_49.createOrReplaceTempView("LY_SW_SALES_DAY_SKU_STORE_RPT_49")

# COMMAND ----------
# DBTITLE 1, EXP_ForecastDay_SWLY_50


query_50 = f"""SELECT
  DAY_DT AS DAY_DT,
  ADD_TO_DATE(DAY_DT, 'DAY', -7) AS DAY_DT_LY,
  LOCATION_ID AS LOCATION_ID,
  DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  SALES_QTY AS SALES_QTY,
  SAP_CLASS_ID AS SAP_CLASS_ID,
  trunc(
    ADD_TO_DATE(
      ADD_TO_DATE(
        ADD_TO_DATE(
          PROCESS_DT,
          'D',
          TO_INTEGER(TO_CHAR(PROCESS_DT, 'D')) * -1
        ),
        'D',
        DAY_OF_WK_NBR
      ),
      'D',
      15
    )
  ) AS FORECAST_DAY,
  SAP_CATEGORY_ID AS SAP_CATEGORY_ID,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  LY_SW_SALES_DAY_SKU_STORE_RPT_49"""

df_50 = spark.sql(query_50)

df_50.createOrReplaceTempView("EXP_ForecastDay_SWLY_50")

# COMMAND ----------
# DBTITLE 1, AGG_SWLY_51


query_51 = f"""SELECT
  DAY_DT AS DAY_DT,
  LOCATION_ID AS LOCATION_ID,
  FORECAST_DAY AS FORECAST_DAY,
  SAP_CATEGORY_ID AS SAP_CATEGORY_ID,
  SUM(IFF(IN(SAP_CLASS_ID, 4921, 822), SALES_QTY, 0)) AS DAY_CAMP,
  SUM(
    IFF(
      IN(SAP_CLASS_ID, 4913)
      OR IN(SAP_CATEGORY_ID, 822001),
      SALES_QTY,
      0
    )
  ) AS BACK_OF_HOUSE,
  last(Monotonically_Increasing_Id) AS Monotonically_Increasing_Id
FROM
  EXP_ForecastDay_SWLY_50
GROUP BY
  DAY_DT,
  LOCATION_ID,
  DAY_OF_WK_NBR,
  FORECAST_DAY"""

df_51 = spark.sql(query_51)

df_51.createOrReplaceTempView("AGG_SWLY_51")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_SITE_PROFILE_RPT_52


query_52 = f"""SELECT
  LOCATION_ID AS LOCATION_ID,
  LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
  LOCATION_TYPE_DESC AS LOCATION_TYPE_DESC,
  STORE_NBR AS STORE_NBR,
  STORE_NAME AS STORE_NAME,
  STORE_TYPE_ID AS STORE_TYPE_ID,
  STORE_TYPE_DESC AS STORE_TYPE_DESC,
  PARENT_LOCATION_ID AS PARENT_LOCATION_ID,
  LOCATION_NBR AS LOCATION_NBR,
  COMPANY_ID AS COMPANY_ID,
  COMPANY_DESC AS COMPANY_DESC,
  SUPER_REGION_ID AS SUPER_REGION_ID,
  SUPER_REGION_DESC AS SUPER_REGION_DESC,
  REGION_ID AS REGION_ID,
  REGION_DESC AS REGION_DESC,
  DISTRICT_ID AS DISTRICT_ID,
  DISTRICT_DESC AS DISTRICT_DESC,
  SITE_ADDRESS AS SITE_ADDRESS,
  SITE_CITY AS SITE_CITY,
  SITE_COUNTY AS SITE_COUNTY,
  STATE_CD AS STATE_CD,
  STATE_NAME AS STATE_NAME,
  POSTAL_CD AS POSTAL_CD,
  COUNTRY_CD AS COUNTRY_CD,
  COUNTRY_NAME AS COUNTRY_NAME,
  GEO_LATITUDE_NBR AS GEO_LATITUDE_NBR,
  GEO_LONGITUDE_NBR AS GEO_LONGITUDE_NBR,
  PETSMART_DMA_CD AS PETSMART_DMA_CD,
  PETSMART_DMA_DESC AS PETSMART_DMA_DESC,
  SITE_MAIN_TELE_NO AS SITE_MAIN_TELE_NO,
  SITE_GROOM_TELE_NO AS SITE_GROOM_TELE_NO,
  SITE_FAX_NO AS SITE_FAX_NO,
  SITE_EMAIL_ADDRESS AS SITE_EMAIL_ADDRESS,
  STORE_OPEN_CLOSE_FLAG AS STORE_OPEN_CLOSE_FLAG,
  SFT_OPEN_DT AS SFT_OPEN_DT,
  OPEN_DT AS OPEN_DT,
  GR_OPEN_DT AS GR_OPEN_DT,
  CLOSE_DT AS CLOSE_DT,
  SITE_SALES_FLAG AS SITE_SALES_FLAG,
  SALES_CURR_FLAG AS SALES_CURR_FLAG,
  SITE_OPEN_YRS_AMT AS SITE_OPEN_YRS_AMT,
  FIRST_SALE_DT AS FIRST_SALE_DT,
  FIRST_MEASURED_SALE_DT AS FIRST_MEASURED_SALE_DT,
  LAST_SALE_DT AS LAST_SALE_DT,
  COMP_CURR_FLAG AS COMP_CURR_FLAG,
  COMP_EFF_DT AS COMP_EFF_DT,
  COMP_END_DT AS COMP_END_DT,
  TP_LOC_FLAG AS TP_LOC_FLAG,
  TP_ACTIVE_CNT AS TP_ACTIVE_CNT,
  TP_START_DT AS TP_START_DT,
  HOTEL_FLAG AS HOTEL_FLAG,
  HOTEL_OPEN_DT AS HOTEL_OPEN_DT,
  DAYCAMP_FLAG AS DAYCAMP_FLAG,
  VET_FLAG AS VET_FLAG,
  TIME_ZONE_ID AS TIME_ZONE_ID,
  TIME_ZONE AS TIME_ZONE,
  SQ_FEET_RETAIL AS SQ_FEET_RETAIL,
  SQ_FEET_TOTAL AS SQ_FEET_TOTAL,
  TRADE_AREA AS TRADE_AREA,
  DELV_SERVICE_CLASS_ID AS DELV_SERVICE_CLASS_ID,
  PICK_SERVICE_CLASS_ID AS PICK_SERVICE_CLASS_ID,
  REPL_DC_NBR AS REPL_DC_NBR,
  REPL_FISH_DC_NBR AS REPL_FISH_DC_NBR,
  REPL_FWD_DC_NBR AS REPL_FWD_DC_NBR,
  PROMO_LABEL_CD AS PROMO_LABEL_CD,
  PRICE_ZONE_ID AS PRICE_ZONE_ID,
  PRICE_ZONE_DESC AS PRICE_ZONE_DESC,
  PRICE_AD_ZONE_ID AS PRICE_AD_ZONE_ID,
  PRICE_AD_ZONE_DESC AS PRICE_AD_ZONE_DESC,
  EQUINE_MERCH_ID AS EQUINE_MERCH_ID,
  EQUINE_MERCH_DESC AS EQUINE_MERCH_DESC,
  EQUINE_SITE_ID AS EQUINE_SITE_ID,
  EQUINE_SITE_DESC AS EQUINE_SITE_DESC,
  EQUINE_SITE_OPEN_DT AS EQUINE_SITE_OPEN_DT,
  LOYALTY_PGM_TYPE_ID AS LOYALTY_PGM_TYPE_ID,
  LOYALTY_PGM_TYPE_DESC AS LOYALTY_PGM_TYPE_DESC,
  LOYALTY_PGM_STATUS_ID AS LOYALTY_PGM_STATUS_ID,
  LOYALTY_PGM_STATUS_DESC AS LOYALTY_PGM_STATUS_DESC,
  LOYALTY_PGM_START_DT AS LOYALTY_PGM_START_DT,
  LOYALTY_PGM_CHANGE_DT AS LOYALTY_PGM_CHANGE_DT,
  BP_COMPANY_NBR AS BP_COMPANY_NBR,
  BP_GL_ACCT AS BP_GL_ACCT,
  SITE_LOGIN_ID AS SITE_LOGIN_ID,
  SITE_MANAGER_ID AS SITE_MANAGER_ID,
  SITE_MANAGER_NAME AS SITE_MANAGER_NAME,
  MGR_ID AS MGR_ID,
  MGR_DESC AS MGR_DESC,
  DVL_ID AS DVL_ID,
  DVL_DESC AS DVL_DESC,
  PURCH_GROUP_ID AS PURCH_GROUP_ID,
  PURCH_GROUP_NAME AS PURCH_GROUP_NAME,
  TOTAL_SALES_RANKING_CD AS TOTAL_SALES_RANKING_CD,
  MERCH_SALES_RANKING_CD AS MERCH_SALES_RANKING_CD,
  SERVICES_SALES_RANKING_CD AS SERVICES_SALES_RANKING_CD,
  SALON_SALES_RANKING_CD AS SALON_SALES_RANKING_CD,
  TRAINING_SALES_RANKING_CD AS TRAINING_SALES_RANKING_CD,
  HOTEL_DDC_SALES_RANKING_CD AS HOTEL_DDC_SALES_RANKING_CD,
  CONSUMABLES_SALES_RANKING_CD AS CONSUMABLES_SALES_RANKING_CD,
  HARDGOODS_SALES_RANKING_CD AS HARDGOODS_SALES_RANKING_CD,
  SPECIALTY_SALES_RANKING_CD AS SPECIALTY_SALES_RANKING_CD,
  DIST_MGR_NAME AS DIST_MGR_NAME,
  DM_EMAIL_ADDRESS AS DM_EMAIL_ADDRESS,
  DC_AREA_DIRECTOR_NAME AS DC_AREA_DIRECTOR_NAME,
  DC_AREA_DIRECTOR_EMAIL AS DC_AREA_DIRECTOR_EMAIL,
  DIST_SVC_MGR_NAME AS DIST_SVC_MGR_NAME,
  DSM_EMAIL_ADDRESS AS DSM_EMAIL_ADDRESS,
  REGION_VP_NAME AS REGION_VP_NAME,
  RVP_EMAIL_ADDRESS AS RVP_EMAIL_ADDRESS,
  REGION_TRAINER_NAME AS REGION_TRAINER_NAME,
  ASSET_PROTECT_NAME AS ASSET_PROTECT_NAME,
  ASSET_PROTECT_EMAIL AS ASSET_PROTECT_EMAIL,
  LP_SAFETY_DIRECTOR_NAME AS LP_SAFETY_DIRECTOR_NAME,
  LP_SAFETY_DIRECTOR_EMAIL AS LP_SAFETY_DIRECTOR_EMAIL,
  SR_LP_SAFETY_MGR_NAME AS SR_LP_SAFETY_MGR_NAME,
  SR_LP_SAFETY_MGR_EMAIL AS SR_LP_SAFETY_MGR_EMAIL,
  REGIONAL_LP_SAFETY_MGR_NAME AS REGIONAL_LP_SAFETY_MGR_NAME,
  REGIONAL_LP_SAFETY_MGR_EMAIL AS REGIONAL_LP_SAFETY_MGR_EMAIL,
  RETAIL_MANAGER_SAFETY_NAME AS RETAIL_MANAGER_SAFETY_NAME,
  RETAIL_MANAGER_SAFETY_EMAIL AS RETAIL_MANAGER_SAFETY_EMAIL,
  DC_GENERAL_MANAGER_NAME AS DC_GENERAL_MANAGER_NAME,
  DC_GENERAL_MANAGER_EMAIL AS DC_GENERAL_MANAGER_EMAIL,
  ASST_DC_GENERAL_MANAGER_NAME1 AS ASST_DC_GENERAL_MANAGER_NAME1,
  ASST_DC_GENERAL_MANAGER_EMAIL1 AS ASST_DC_GENERAL_MANAGER_EMAIL1,
  ASST_DC_GENERAL_MANAGER_NAME2 AS ASST_DC_GENERAL_MANAGER_NAME2,
  ASST_DC_GENERAL_MANAGER_EMAIL2 AS ASST_DC_GENERAL_MANAGER_EMAIL2,
  HR_MANAGER_NAME AS HR_MANAGER_NAME,
  HR_MANAGER_EMAIL AS HR_MANAGER_EMAIL,
  HR_SUPERVISOR_NAME1 AS HR_SUPERVISOR_NAME1,
  HR_SUPERVISOR_EMAIL1 AS HR_SUPERVISOR_EMAIL1,
  HR_SUPERVISOR_NAME2 AS HR_SUPERVISOR_NAME2,
  HR_SUPERVISOR_EMAIL2 AS HR_SUPERVISOR_EMAIL2,
  LEARN_SOLUTION_MGR_NAME AS LEARN_SOLUTION_MGR_NAME,
  LEARN_SOLUTION_MGR_EMAIL AS LEARN_SOLUTION_MGR_EMAIL,
  ADD_DT AS ADD_DT,
  DELETE_DT AS DELETE_DT,
  UPDATE_DT AS UPDATE_DT,
  LOAD_DT AS LOAD_DT
FROM
  SITE_PROFILE_RPT"""

df_52 = spark.sql(query_52)

df_52.createOrReplaceTempView("Shortcut_to_SITE_PROFILE_RPT_52")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_SITE_PROFILE_RPT1_53


query_53 = f"""SELECT
  LOCATION_ID AS LOCATION_ID,
  LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
  LOCATION_TYPE_DESC AS LOCATION_TYPE_DESC,
  STORE_NBR AS STORE_NBR,
  STORE_NAME AS STORE_NAME,
  STORE_TYPE_ID AS STORE_TYPE_ID,
  STORE_TYPE_DESC AS STORE_TYPE_DESC,
  PARENT_LOCATION_ID AS PARENT_LOCATION_ID,
  LOCATION_NBR AS LOCATION_NBR,
  COMPANY_ID AS COMPANY_ID,
  COMPANY_DESC AS COMPANY_DESC,
  SUPER_REGION_ID AS SUPER_REGION_ID,
  SUPER_REGION_DESC AS SUPER_REGION_DESC,
  REGION_ID AS REGION_ID,
  REGION_DESC AS REGION_DESC,
  DISTRICT_ID AS DISTRICT_ID,
  DISTRICT_DESC AS DISTRICT_DESC,
  SITE_ADDRESS AS SITE_ADDRESS,
  SITE_CITY AS SITE_CITY,
  SITE_COUNTY AS SITE_COUNTY,
  STATE_CD AS STATE_CD,
  STATE_NAME AS STATE_NAME,
  POSTAL_CD AS POSTAL_CD,
  COUNTRY_CD AS COUNTRY_CD,
  COUNTRY_NAME AS COUNTRY_NAME,
  GEO_LATITUDE_NBR AS GEO_LATITUDE_NBR,
  GEO_LONGITUDE_NBR AS GEO_LONGITUDE_NBR,
  PETSMART_DMA_CD AS PETSMART_DMA_CD,
  PETSMART_DMA_DESC AS PETSMART_DMA_DESC,
  SITE_MAIN_TELE_NO AS SITE_MAIN_TELE_NO,
  SITE_GROOM_TELE_NO AS SITE_GROOM_TELE_NO,
  SITE_FAX_NO AS SITE_FAX_NO,
  SITE_EMAIL_ADDRESS AS SITE_EMAIL_ADDRESS,
  STORE_OPEN_CLOSE_FLAG AS STORE_OPEN_CLOSE_FLAG,
  SFT_OPEN_DT AS SFT_OPEN_DT,
  OPEN_DT AS OPEN_DT,
  GR_OPEN_DT AS GR_OPEN_DT,
  CLOSE_DT AS CLOSE_DT,
  SITE_SALES_FLAG AS SITE_SALES_FLAG,
  SALES_CURR_FLAG AS SALES_CURR_FLAG,
  SITE_OPEN_YRS_AMT AS SITE_OPEN_YRS_AMT,
  FIRST_SALE_DT AS FIRST_SALE_DT,
  FIRST_MEASURED_SALE_DT AS FIRST_MEASURED_SALE_DT,
  LAST_SALE_DT AS LAST_SALE_DT,
  COMP_CURR_FLAG AS COMP_CURR_FLAG,
  COMP_EFF_DT AS COMP_EFF_DT,
  COMP_END_DT AS COMP_END_DT,
  TP_LOC_FLAG AS TP_LOC_FLAG,
  TP_ACTIVE_CNT AS TP_ACTIVE_CNT,
  TP_START_DT AS TP_START_DT,
  HOTEL_FLAG AS HOTEL_FLAG,
  HOTEL_OPEN_DT AS HOTEL_OPEN_DT,
  DAYCAMP_FLAG AS DAYCAMP_FLAG,
  VET_FLAG AS VET_FLAG,
  TIME_ZONE_ID AS TIME_ZONE_ID,
  TIME_ZONE AS TIME_ZONE,
  SQ_FEET_RETAIL AS SQ_FEET_RETAIL,
  SQ_FEET_TOTAL AS SQ_FEET_TOTAL,
  TRADE_AREA AS TRADE_AREA,
  DELV_SERVICE_CLASS_ID AS DELV_SERVICE_CLASS_ID,
  PICK_SERVICE_CLASS_ID AS PICK_SERVICE_CLASS_ID,
  REPL_DC_NBR AS REPL_DC_NBR,
  REPL_FISH_DC_NBR AS REPL_FISH_DC_NBR,
  REPL_FWD_DC_NBR AS REPL_FWD_DC_NBR,
  PROMO_LABEL_CD AS PROMO_LABEL_CD,
  PRICE_ZONE_ID AS PRICE_ZONE_ID,
  PRICE_ZONE_DESC AS PRICE_ZONE_DESC,
  PRICE_AD_ZONE_ID AS PRICE_AD_ZONE_ID,
  PRICE_AD_ZONE_DESC AS PRICE_AD_ZONE_DESC,
  EQUINE_MERCH_ID AS EQUINE_MERCH_ID,
  EQUINE_MERCH_DESC AS EQUINE_MERCH_DESC,
  EQUINE_SITE_ID AS EQUINE_SITE_ID,
  EQUINE_SITE_DESC AS EQUINE_SITE_DESC,
  EQUINE_SITE_OPEN_DT AS EQUINE_SITE_OPEN_DT,
  LOYALTY_PGM_TYPE_ID AS LOYALTY_PGM_TYPE_ID,
  LOYALTY_PGM_TYPE_DESC AS LOYALTY_PGM_TYPE_DESC,
  LOYALTY_PGM_STATUS_ID AS LOYALTY_PGM_STATUS_ID,
  LOYALTY_PGM_STATUS_DESC AS LOYALTY_PGM_STATUS_DESC,
  LOYALTY_PGM_START_DT AS LOYALTY_PGM_START_DT,
  LOYALTY_PGM_CHANGE_DT AS LOYALTY_PGM_CHANGE_DT,
  BP_COMPANY_NBR AS BP_COMPANY_NBR,
  BP_GL_ACCT AS BP_GL_ACCT,
  SITE_LOGIN_ID AS SITE_LOGIN_ID,
  SITE_MANAGER_ID AS SITE_MANAGER_ID,
  SITE_MANAGER_NAME AS SITE_MANAGER_NAME,
  MGR_ID AS MGR_ID,
  MGR_DESC AS MGR_DESC,
  DVL_ID AS DVL_ID,
  DVL_DESC AS DVL_DESC,
  PURCH_GROUP_ID AS PURCH_GROUP_ID,
  PURCH_GROUP_NAME AS PURCH_GROUP_NAME,
  TOTAL_SALES_RANKING_CD AS TOTAL_SALES_RANKING_CD,
  MERCH_SALES_RANKING_CD AS MERCH_SALES_RANKING_CD,
  SERVICES_SALES_RANKING_CD AS SERVICES_SALES_RANKING_CD,
  SALON_SALES_RANKING_CD AS SALON_SALES_RANKING_CD,
  TRAINING_SALES_RANKING_CD AS TRAINING_SALES_RANKING_CD,
  HOTEL_DDC_SALES_RANKING_CD AS HOTEL_DDC_SALES_RANKING_CD,
  CONSUMABLES_SALES_RANKING_CD AS CONSUMABLES_SALES_RANKING_CD,
  HARDGOODS_SALES_RANKING_CD AS HARDGOODS_SALES_RANKING_CD,
  SPECIALTY_SALES_RANKING_CD AS SPECIALTY_SALES_RANKING_CD,
  DIST_MGR_NAME AS DIST_MGR_NAME,
  DM_EMAIL_ADDRESS AS DM_EMAIL_ADDRESS,
  DC_AREA_DIRECTOR_NAME AS DC_AREA_DIRECTOR_NAME,
  DC_AREA_DIRECTOR_EMAIL AS DC_AREA_DIRECTOR_EMAIL,
  DIST_SVC_MGR_NAME AS DIST_SVC_MGR_NAME,
  DSM_EMAIL_ADDRESS AS DSM_EMAIL_ADDRESS,
  REGION_VP_NAME AS REGION_VP_NAME,
  RVP_EMAIL_ADDRESS AS RVP_EMAIL_ADDRESS,
  REGION_TRAINER_NAME AS REGION_TRAINER_NAME,
  ASSET_PROTECT_NAME AS ASSET_PROTECT_NAME,
  ASSET_PROTECT_EMAIL AS ASSET_PROTECT_EMAIL,
  LP_SAFETY_DIRECTOR_NAME AS LP_SAFETY_DIRECTOR_NAME,
  LP_SAFETY_DIRECTOR_EMAIL AS LP_SAFETY_DIRECTOR_EMAIL,
  SR_LP_SAFETY_MGR_NAME AS SR_LP_SAFETY_MGR_NAME,
  SR_LP_SAFETY_MGR_EMAIL AS SR_LP_SAFETY_MGR_EMAIL,
  REGIONAL_LP_SAFETY_MGR_NAME AS REGIONAL_LP_SAFETY_MGR_NAME,
  REGIONAL_LP_SAFETY_MGR_EMAIL AS REGIONAL_LP_SAFETY_MGR_EMAIL,
  RETAIL_MANAGER_SAFETY_NAME AS RETAIL_MANAGER_SAFETY_NAME,
  RETAIL_MANAGER_SAFETY_EMAIL AS RETAIL_MANAGER_SAFETY_EMAIL,
  DC_GENERAL_MANAGER_NAME AS DC_GENERAL_MANAGER_NAME,
  DC_GENERAL_MANAGER_EMAIL AS DC_GENERAL_MANAGER_EMAIL,
  ASST_DC_GENERAL_MANAGER_NAME1 AS ASST_DC_GENERAL_MANAGER_NAME1,
  ASST_DC_GENERAL_MANAGER_EMAIL1 AS ASST_DC_GENERAL_MANAGER_EMAIL1,
  ASST_DC_GENERAL_MANAGER_NAME2 AS ASST_DC_GENERAL_MANAGER_NAME2,
  ASST_DC_GENERAL_MANAGER_EMAIL2 AS ASST_DC_GENERAL_MANAGER_EMAIL2,
  HR_MANAGER_NAME AS HR_MANAGER_NAME,
  HR_MANAGER_EMAIL AS HR_MANAGER_EMAIL,
  HR_SUPERVISOR_NAME1 AS HR_SUPERVISOR_NAME1,
  HR_SUPERVISOR_EMAIL1 AS HR_SUPERVISOR_EMAIL1,
  HR_SUPERVISOR_NAME2 AS HR_SUPERVISOR_NAME2,
  HR_SUPERVISOR_EMAIL2 AS HR_SUPERVISOR_EMAIL2,
  LEARN_SOLUTION_MGR_NAME AS LEARN_SOLUTION_MGR_NAME,
  LEARN_SOLUTION_MGR_EMAIL AS LEARN_SOLUTION_MGR_EMAIL,
  ADD_DT AS ADD_DT,
  DELETE_DT AS DELETE_DT,
  UPDATE_DT AS UPDATE_DT,
  LOAD_DT AS LOAD_DT
FROM
  SITE_PROFILE_RPT"""

df_53 = spark.sql(query_53)

df_53.createOrReplaceTempView("Shortcut_to_SITE_PROFILE_RPT1_53")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_SITE_PROFILE_RPT11_54


query_54 = f"""SELECT
  LOCATION_ID AS LOCATION_ID,
  LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
  LOCATION_TYPE_DESC AS LOCATION_TYPE_DESC,
  STORE_NBR AS STORE_NBR,
  STORE_NAME AS STORE_NAME,
  STORE_TYPE_ID AS STORE_TYPE_ID,
  STORE_TYPE_DESC AS STORE_TYPE_DESC,
  PARENT_LOCATION_ID AS PARENT_LOCATION_ID,
  LOCATION_NBR AS LOCATION_NBR,
  COMPANY_ID AS COMPANY_ID,
  COMPANY_DESC AS COMPANY_DESC,
  SUPER_REGION_ID AS SUPER_REGION_ID,
  SUPER_REGION_DESC AS SUPER_REGION_DESC,
  REGION_ID AS REGION_ID,
  REGION_DESC AS REGION_DESC,
  DISTRICT_ID AS DISTRICT_ID,
  DISTRICT_DESC AS DISTRICT_DESC,
  SITE_ADDRESS AS SITE_ADDRESS,
  SITE_CITY AS SITE_CITY,
  SITE_COUNTY AS SITE_COUNTY,
  STATE_CD AS STATE_CD,
  STATE_NAME AS STATE_NAME,
  POSTAL_CD AS POSTAL_CD,
  COUNTRY_CD AS COUNTRY_CD,
  COUNTRY_NAME AS COUNTRY_NAME,
  GEO_LATITUDE_NBR AS GEO_LATITUDE_NBR,
  GEO_LONGITUDE_NBR AS GEO_LONGITUDE_NBR,
  PETSMART_DMA_CD AS PETSMART_DMA_CD,
  PETSMART_DMA_DESC AS PETSMART_DMA_DESC,
  SITE_MAIN_TELE_NO AS SITE_MAIN_TELE_NO,
  SITE_GROOM_TELE_NO AS SITE_GROOM_TELE_NO,
  SITE_FAX_NO AS SITE_FAX_NO,
  SITE_EMAIL_ADDRESS AS SITE_EMAIL_ADDRESS,
  STORE_OPEN_CLOSE_FLAG AS STORE_OPEN_CLOSE_FLAG,
  SFT_OPEN_DT AS SFT_OPEN_DT,
  OPEN_DT AS OPEN_DT,
  GR_OPEN_DT AS GR_OPEN_DT,
  CLOSE_DT AS CLOSE_DT,
  SITE_SALES_FLAG AS SITE_SALES_FLAG,
  SALES_CURR_FLAG AS SALES_CURR_FLAG,
  SITE_OPEN_YRS_AMT AS SITE_OPEN_YRS_AMT,
  FIRST_SALE_DT AS FIRST_SALE_DT,
  FIRST_MEASURED_SALE_DT AS FIRST_MEASURED_SALE_DT,
  LAST_SALE_DT AS LAST_SALE_DT,
  COMP_CURR_FLAG AS COMP_CURR_FLAG,
  COMP_EFF_DT AS COMP_EFF_DT,
  COMP_END_DT AS COMP_END_DT,
  TP_LOC_FLAG AS TP_LOC_FLAG,
  TP_ACTIVE_CNT AS TP_ACTIVE_CNT,
  TP_START_DT AS TP_START_DT,
  HOTEL_FLAG AS HOTEL_FLAG,
  HOTEL_OPEN_DT AS HOTEL_OPEN_DT,
  DAYCAMP_FLAG AS DAYCAMP_FLAG,
  VET_FLAG AS VET_FLAG,
  TIME_ZONE_ID AS TIME_ZONE_ID,
  TIME_ZONE AS TIME_ZONE,
  SQ_FEET_RETAIL AS SQ_FEET_RETAIL,
  SQ_FEET_TOTAL AS SQ_FEET_TOTAL,
  TRADE_AREA AS TRADE_AREA,
  DELV_SERVICE_CLASS_ID AS DELV_SERVICE_CLASS_ID,
  PICK_SERVICE_CLASS_ID AS PICK_SERVICE_CLASS_ID,
  REPL_DC_NBR AS REPL_DC_NBR,
  REPL_FISH_DC_NBR AS REPL_FISH_DC_NBR,
  REPL_FWD_DC_NBR AS REPL_FWD_DC_NBR,
  PROMO_LABEL_CD AS PROMO_LABEL_CD,
  PRICE_ZONE_ID AS PRICE_ZONE_ID,
  PRICE_ZONE_DESC AS PRICE_ZONE_DESC,
  PRICE_AD_ZONE_ID AS PRICE_AD_ZONE_ID,
  PRICE_AD_ZONE_DESC AS PRICE_AD_ZONE_DESC,
  EQUINE_MERCH_ID AS EQUINE_MERCH_ID,
  EQUINE_MERCH_DESC AS EQUINE_MERCH_DESC,
  EQUINE_SITE_ID AS EQUINE_SITE_ID,
  EQUINE_SITE_DESC AS EQUINE_SITE_DESC,
  EQUINE_SITE_OPEN_DT AS EQUINE_SITE_OPEN_DT,
  LOYALTY_PGM_TYPE_ID AS LOYALTY_PGM_TYPE_ID,
  LOYALTY_PGM_TYPE_DESC AS LOYALTY_PGM_TYPE_DESC,
  LOYALTY_PGM_STATUS_ID AS LOYALTY_PGM_STATUS_ID,
  LOYALTY_PGM_STATUS_DESC AS LOYALTY_PGM_STATUS_DESC,
  LOYALTY_PGM_START_DT AS LOYALTY_PGM_START_DT,
  LOYALTY_PGM_CHANGE_DT AS LOYALTY_PGM_CHANGE_DT,
  BP_COMPANY_NBR AS BP_COMPANY_NBR,
  BP_GL_ACCT AS BP_GL_ACCT,
  SITE_LOGIN_ID AS SITE_LOGIN_ID,
  SITE_MANAGER_ID AS SITE_MANAGER_ID,
  SITE_MANAGER_NAME AS SITE_MANAGER_NAME,
  MGR_ID AS MGR_ID,
  MGR_DESC AS MGR_DESC,
  DVL_ID AS DVL_ID,
  DVL_DESC AS DVL_DESC,
  PURCH_GROUP_ID AS PURCH_GROUP_ID,
  PURCH_GROUP_NAME AS PURCH_GROUP_NAME,
  TOTAL_SALES_RANKING_CD AS TOTAL_SALES_RANKING_CD,
  MERCH_SALES_RANKING_CD AS MERCH_SALES_RANKING_CD,
  SERVICES_SALES_RANKING_CD AS SERVICES_SALES_RANKING_CD,
  SALON_SALES_RANKING_CD AS SALON_SALES_RANKING_CD,
  TRAINING_SALES_RANKING_CD AS TRAINING_SALES_RANKING_CD,
  HOTEL_DDC_SALES_RANKING_CD AS HOTEL_DDC_SALES_RANKING_CD,
  CONSUMABLES_SALES_RANKING_CD AS CONSUMABLES_SALES_RANKING_CD,
  HARDGOODS_SALES_RANKING_CD AS HARDGOODS_SALES_RANKING_CD,
  SPECIALTY_SALES_RANKING_CD AS SPECIALTY_SALES_RANKING_CD,
  DIST_MGR_NAME AS DIST_MGR_NAME,
  DM_EMAIL_ADDRESS AS DM_EMAIL_ADDRESS,
  DC_AREA_DIRECTOR_NAME AS DC_AREA_DIRECTOR_NAME,
  DC_AREA_DIRECTOR_EMAIL AS DC_AREA_DIRECTOR_EMAIL,
  DIST_SVC_MGR_NAME AS DIST_SVC_MGR_NAME,
  DSM_EMAIL_ADDRESS AS DSM_EMAIL_ADDRESS,
  REGION_VP_NAME AS REGION_VP_NAME,
  RVP_EMAIL_ADDRESS AS RVP_EMAIL_ADDRESS,
  REGION_TRAINER_NAME AS REGION_TRAINER_NAME,
  ASSET_PROTECT_NAME AS ASSET_PROTECT_NAME,
  ASSET_PROTECT_EMAIL AS ASSET_PROTECT_EMAIL,
  LP_SAFETY_DIRECTOR_NAME AS LP_SAFETY_DIRECTOR_NAME,
  LP_SAFETY_DIRECTOR_EMAIL AS LP_SAFETY_DIRECTOR_EMAIL,
  SR_LP_SAFETY_MGR_NAME AS SR_LP_SAFETY_MGR_NAME,
  SR_LP_SAFETY_MGR_EMAIL AS SR_LP_SAFETY_MGR_EMAIL,
  REGIONAL_LP_SAFETY_MGR_NAME AS REGIONAL_LP_SAFETY_MGR_NAME,
  REGIONAL_LP_SAFETY_MGR_EMAIL AS REGIONAL_LP_SAFETY_MGR_EMAIL,
  RETAIL_MANAGER_SAFETY_NAME AS RETAIL_MANAGER_SAFETY_NAME,
  RETAIL_MANAGER_SAFETY_EMAIL AS RETAIL_MANAGER_SAFETY_EMAIL,
  DC_GENERAL_MANAGER_NAME AS DC_GENERAL_MANAGER_NAME,
  DC_GENERAL_MANAGER_EMAIL AS DC_GENERAL_MANAGER_EMAIL,
  ASST_DC_GENERAL_MANAGER_NAME1 AS ASST_DC_GENERAL_MANAGER_NAME1,
  ASST_DC_GENERAL_MANAGER_EMAIL1 AS ASST_DC_GENERAL_MANAGER_EMAIL1,
  ASST_DC_GENERAL_MANAGER_NAME2 AS ASST_DC_GENERAL_MANAGER_NAME2,
  ASST_DC_GENERAL_MANAGER_EMAIL2 AS ASST_DC_GENERAL_MANAGER_EMAIL2,
  HR_MANAGER_NAME AS HR_MANAGER_NAME,
  HR_MANAGER_EMAIL AS HR_MANAGER_EMAIL,
  HR_SUPERVISOR_NAME1 AS HR_SUPERVISOR_NAME1,
  HR_SUPERVISOR_EMAIL1 AS HR_SUPERVISOR_EMAIL1,
  HR_SUPERVISOR_NAME2 AS HR_SUPERVISOR_NAME2,
  HR_SUPERVISOR_EMAIL2 AS HR_SUPERVISOR_EMAIL2,
  LEARN_SOLUTION_MGR_NAME AS LEARN_SOLUTION_MGR_NAME,
  LEARN_SOLUTION_MGR_EMAIL AS LEARN_SOLUTION_MGR_EMAIL,
  ADD_DT AS ADD_DT,
  DELETE_DT AS DELETE_DT,
  UPDATE_DT AS UPDATE_DT,
  LOAD_DT AS LOAD_DT
FROM
  SITE_PROFILE_RPT"""

df_54 = spark.sql(query_54)

df_54.createOrReplaceTempView("Shortcut_to_SITE_PROFILE_RPT11_54")

# COMMAND ----------
# DBTITLE 1, SQ_LY_SW_MISSING_DAYS_55


query_55 = f"""SELECT
  DISTINCT Shortcut_to_PS2_HTL_ETL_CONTROL11_5.PS2_HTL_RUN_DT AS PS2_HTL_RUN_DT,
  Shortcut_to_DAYS11_24.DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  Shortcut_to_SITE_PROFILE_RPT11_54.STORE_NBR AS STORE_NBR,
  PS2_DAYS_TY_LY.DAY_DT AS DAY_DT,
  TPS.LOCATION_ID AS LOCATION_ID,
  ODD.DAY_CAMP_CNT AS DAY_CAMP_CNT,
  ODD.DAY_CARE_CNT AS DAY_CARE_CNT,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_PS2_HTL_OCCUPANCY_DATA_DEFAULT11_8 ODD,
  Shortcut_to_DAYS11_24,
  PS2_DAYS_TY_LY,
  Shortcut_to_PS2_HTL_ETL_CONTROL11_5,
  Shortcut_to_SITE_PROFILE_RPT11_54,
  (
    SELECT
      DISTINCT TP.LOCATION_ID
    FROM
      Shortcut_to_TP_SERVICE_SCHEDULE11_13 TP,
      Shortcut_to_PS2_HTL_ETL_CONTROL11_5 PC
    WHERE
      TP.ROOM_TYPE_ID IN (2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16)
      AND TP.FOLIO_STATUS_FLAG IN ('A', 'I')
      AND PC.PS2_HTL_PROCESS_ID = 1
      AND TP.DAY_DT < PC.PS2_HTL_RUN_DT + 21
      AND TP.DAY_DT > PC.PS2_HTL_RUN_DT + 13
  ) TPS
WHERE
  Shortcut_to_DAYS11_24.DAY_DT < Shortcut_to_PS2_HTL_ETL_CONTROL11_5.PS2_HTL_RUN_DT + 21
  AND Shortcut_to_DAYS11_24.DAY_DT > Shortcut_to_PS2_HTL_ETL_CONTROL11_5.PS2_HTL_RUN_DT + 13
  AND Shortcut_to_PS2_HTL_ETL_CONTROL11_5.PS2_HTL_PROCESS_ID = 1
  AND TPS.LOCATION_ID = Shortcut_to_SITE_PROFILE_RPT11_54.LOCATION_ID
  AND Shortcut_to_DAYS11_24.DAY_DT = PS2_DAYS_TY_LY.DAY_DT
  AND PS2_DAYS_TY_LY.TRANS_DAY_DT = ODD.DAY_DT
  AND PS2_DAYS_TY_LY.TY_LY_FLAG = 'LY'"""

df_55 = spark.sql(query_55)

df_55.createOrReplaceTempView("SQ_LY_SW_MISSING_DAYS_55")

# COMMAND ----------
# DBTITLE 1, JNR_LY_SW_MISSING_DAY_56


query_56 = f"""SELECT
  DETAIL.PS2_HTL_RUN_DT AS PS2_HTL_RUN_DT,
  DETAIL.DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  DETAIL.STORE_NBR AS STORE_NBR,
  DETAIL.DAY_DT AS DAY_DT,
  DETAIL.LOCATION_ID AS LOCATION_ID,
  DETAIL.DAY_CAMP_CNT AS DAY_CAMP_CNT,
  DETAIL.DAY_CARE_CNT AS DAY_CARE_CNT,
  MASTER.DAY_DT AS DAY_DT1,
  MASTER.LOCATION_ID AS LOCATION_ID1,
  MASTER.FORECAST_DAY AS FORECAST_DAY,
  MASTER.DAY_CAMP AS DAY_CAMP,
  MASTER.BACK_OF_HOUSE AS DAY_CARE,
  DETAIL.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  AGG_SWLY_51 MASTER
  RIGHT JOIN SQ_LY_SW_MISSING_DAYS_55 DETAIL ON MASTER.DAY_DT = DETAIL.DAY_DT
  AND MASTER.LOCATION_ID = DETAIL.LOCATION_ID"""

df_56 = spark.sql(query_56)

df_56.createOrReplaceTempView("JNR_LY_SW_MISSING_DAY_56")

# COMMAND ----------
# DBTITLE 1, EXP_LY_SW_57


query_57 = f"""SELECT
  IFF(
    ISNULL(FORECAST_DAY),
    trunc(
      ADD_TO_DATE(
        ADD_TO_DATE(
          ADD_TO_DATE(
            PS2_HTL_RUN_DT,
            'D',
            TO_INTEGER(TO_CHAR(PS2_HTL_RUN_DT, 'D')) * -1
          ),
          'D',
          DAY_OF_WK_NBR
        ),
        'D',
        15
      )
    ),
    FORECAST_DAY
  ) AS SWLY_FORECAST_DAY,
  IFF(ISNULL(DAY_DT1), DAY_DT, DAY_DT1) AS SWLY_DAY_DT,
  IFF(ISNULL(LOCATION_ID1), LOCATION_ID, LOCATION_ID1) AS SWLY_LOCATION_ID,
  IFF(ISNULL(DAY_CAMP), DAY_CAMP_CNT, DAY_CAMP) AS SWLY_DAY_CAMP,
  IFF(ISNULL(DAY_CARE), DAY_CARE_CNT, DAY_CARE) AS SWLY_DAY_CARE,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  JNR_LY_SW_MISSING_DAY_56"""

df_57 = spark.sql(query_57)

df_57.createOrReplaceTempView("EXP_LY_SW_57")

# COMMAND ----------
# DBTITLE 1, JNR_SWLY_58


query_58 = f"""SELECT
  MASTER.FORECAST_DAY AS FORECAST_DAY,
  MASTER.LOCATION_ID AS LOCATION_ID,
  MASTER.WEEK_DT AS WEEK_DT,
  MASTER.DAY_OF_WK_NBR AS DAY_OF_WK_NBR,
  MASTER.DAY_CAMP_CNT AS DAY_CAMP_CNT,
  MASTER.BACK_OF_HOUSE_CNT AS BACK_OF_HOUSE,
  DETAIL.SWLY_LOCATION_ID AS SWLY_LOCATION_ID,
  DETAIL.SWLY_FORECAST_DAY AS SWLY_FORECAST_DAY,
  DETAIL.SWLY_DAY_CAMP AS SWLY_DAY_CAMP,
  DETAIL.SWLY_DAY_CARE AS SWLY_BACK_OF_HOUSE,
  MASTER.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  AGG_Weight_47 MASTER
  LEFT JOIN EXP_LY_SW_57 DETAIL ON MASTER.FORECAST_DAY = DETAIL.SWLY_FORECAST_DAY
  AND MASTER.LOCATION_ID = DETAIL.SWLY_LOCATION_ID"""

df_58 = spark.sql(query_58)

df_58.createOrReplaceTempView("JNR_SWLY_58")

# COMMAND ----------
# DBTITLE 1, EXP_Final_59


query_59 = f"""SELECT
  FORECAST_DAY AS FORECAST_DAY1,
  LOCATION_ID AS LOCATION_ID1,
  TRUNC(
    IFF(ISNULL(SWLY_DAY_CAMP), 0, SWLY_DAY_CAMP) + (
      IFF(ISNULL(SWLY_DAY_CAMP), 0, SWLY_DAY_CAMP) * DAY_CAMP_CNT
    )
  ) AS DAY_CAMP_PLAYROOM_CNT,
  TRUNC(
    IFF(ISNULL(SWLY_BACK_OF_HOUSE), 0, SWLY_BACK_OF_HOUSE) + (
      IFF(ISNULL(SWLY_BACK_OF_HOUSE), 0, SWLY_BACK_OF_HOUSE) * BACK_OF_HOUSE
    )
  ) AS DAY_CARE_CNT,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  JNR_SWLY_58"""

df_59 = spark.sql(query_59)

df_59.createOrReplaceTempView("EXP_Final_59")

# COMMAND ----------
# DBTITLE 1, UPD_DAY_CP_CARE_60


query_60 = f"""SELECT
  FORECAST_DAY1 AS FORECAST_DAY1,
  LOCATION_ID1 AS LOCATION_ID1,
  DAY_CAMP_PLAYROOM_CNT AS DAY_CAMP_PLAYROOM_CNT,
  DAY_CARE_CNT AS DAY_CARE_CNT,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  EXP_Final_59"""

df_60 = spark.sql(query_60)

df_60.createOrReplaceTempView("UPD_DAY_CP_CARE_60")

# COMMAND ----------
# DBTITLE 1, UPD_PS2_HTL_FORECAST_SWLY_TOTAL_PRE_61


query_61 = f"""SELECT
  SWLY_FORECAST_DAY AS FORECAST_DAY,
  SWLY_DAY_DT AS DAY_DT,
  SWLY_LOCATION_ID AS LOCATION_ID,
  SWLY_DAY_CAMP AS SWLY_DAY_CAMP_PLAYROOM,
  SWLY_DAY_CARE AS SWLY_DAY_CARE,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  EXP_LY_SW_57"""

df_61 = spark.sql(query_61)

df_61.createOrReplaceTempView("UPD_PS2_HTL_FORECAST_SWLY_TOTAL_PRE_61")

# COMMAND ----------
# DBTITLE 1, PS2_HTL_FORECAST_TY_LY_TOTAL_PRE


spark.sql("""MERGE INTO PS2_HTL_FORECAST_TY_LY_TOTAL_PRE AS TARGET
USING
  UPD_PS2_HTL_FORECAST_TY_LY_TOTAL_PRE_38 AS SOURCE ON TARGET.LOCATION_ID = SOURCE.LOCATION_ID
  AND TARGET.FORECAST_DAY_DT = SOURCE.FORECAST_DAY
  AND TARGET.DAY_DT = SOURCE.DAY_DT
  WHEN MATCHED THEN
UPDATE
SET
  TARGET.FORECAST_DAY_DT = SOURCE.FORECAST_DAY,
  TARGET.DAY_DT = SOURCE.DAY_DT,
  TARGET.LOCATION_ID = SOURCE.LOCATION_ID,
  TARGET.TY_DAY_CAMP_PLAYROOM = SOURCE.TY_DAY_CAMP_PLAYROOM,
  TARGET.LY_DAY_CAMP_PLAYROOM = SOURCE.LY_DAY_CAMP_PLAYROOM,
  TARGET.TY_DAY_CARE = SOURCE.TY_DAY_CARE,
  TARGET.LY_DAY_CARE = SOURCE.LY_DAY_CARE""")

# COMMAND ----------
# DBTITLE 1, PS2_HTL_FORECAST_SWLY_TOTAL_PRE


spark.sql("""MERGE INTO PS2_HTL_FORECAST_SWLY_TOTAL_PRE AS TARGET
USING
  UPD_PS2_HTL_FORECAST_SWLY_TOTAL_PRE_61 AS SOURCE ON TARGET.LOCATION_ID = SOURCE.LOCATION_ID
  AND TARGET.FORECAST_DAY_DT = SOURCE.FORECAST_DAY
  AND TARGET.DAY_DT = SOURCE.DAY_DT
  WHEN MATCHED THEN
UPDATE
SET
  TARGET.FORECAST_DAY_DT = SOURCE.FORECAST_DAY,
  TARGET.DAY_DT = SOURCE.DAY_DT,
  TARGET.LOCATION_ID = SOURCE.LOCATION_ID,
  TARGET.SWLY_DAY_CAMP_PLAYROOM = SOURCE.SWLY_DAY_CAMP_PLAYROOM,
  TARGET.SWLY_DAY_CARE = SOURCE.SWLY_DAY_CARE""")

# COMMAND ----------
# DBTITLE 1, PS2_HTL_FORECAST_PRE


spark.sql("""MERGE INTO PS2_HTL_FORECAST_PRE AS TARGET
USING
  UPD_DAY_CP_CARE_60 AS SOURCE ON TARGET.LOCATION_ID = SOURCE.LOCATION_ID1
  AND TARGET.FORECAST_DAY_DT = SOURCE.FORECAST_DAY1
  WHEN MATCHED THEN
UPDATE
SET
  TARGET.FORECAST_DAY_DT = SOURCE.FORECAST_DAY1,
  TARGET.LOCATION_ID = SOURCE.LOCATION_ID1,
  TARGET.DAY_CARE_CNT = SOURCE.DAY_CARE_CNT,
  TARGET.DAY_CAMP_CNT = SOURCE.DAY_CAMP_PLAYROOM_CNT""")

# COMMAND ----------
#Post session variable updation
updateVariable(postVariableAssignment, variablesTableName, mainWorkflowId, parentName, "m_ps2_htl_forecast_pre_UPDATE2")

# COMMAND ----------
#Update Mapping Variables in database.
persistVariables(variablesTableName, "m_ps2_htl_forecast_pre_UPDATE2", mainWorkflowId, parentName)
