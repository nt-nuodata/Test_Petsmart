# Databricks notebook source
# MAGIC %run "./udf_informatica"

# COMMAND ----------


from pyspark.sql.types import *

spark.sql("use DELTA_TRAINING")
spark.sql("set spark.sql.legacy.timeParserPolicy = LEGACY")

# COMMAND ----------
%run ./MappingUtility

# COMMAND ----------
mainWorkflowId = dbutils.widgets.get("mainWorkflowId")
mainWorkflowRunId = dbutils.widgets.get("mainWorkflowRunId")
parentName = dbutils.widgets.get("parentName")
preVariableAssignment = dbutils.widgets.get("preVariableAssignment")
postVariableAssignment = dbutils.widgets.get("postVariableAssignment")
truncTargetTableOptions = dbutils.widgets.get("truncTargetTableOptions")
variablesTableName = dbutils.widgets.get("variablesTableName")

# COMMAND ----------
#Truncate Target Tables
truncateTargetTables(truncTargetTableOptions)

# COMMAND ----------
#Pre presession variable updation
updateVariable(preVariableAssignment, variablesTableName, mainWorkflowId, parentName, "m_ps2_htl_PlayroomCapacity")

# COMMAND ----------
fetchAndCreateVariables(parentName,"m_ps2_htl_PlayroomCapacity", variablesTableName, mainWorkflowId)

# COMMAND ----------
# DBTITLE 1, Shortcut_to_UDH_PS2_HTL_PLAYROOM_CAPACITY_0


query_0 = f"""SELECT
  STORE_NBR AS STORE_NBR,
  EFF_DT AS EFF_DT,
  END_DT AS END_DT,
  DAY_OF_WEEK AS DAY_OF_WEEK,
  NORMAL_HRS_ROOM_QTY AS NORMAL_HRS_ROOM_QTY,
  PLAYROOM_01_CAPACITY AS PLAYROOM_01_CAPACITY,
  PLAYROOM_02_CAPACITY AS PLAYROOM_02_CAPACITY,
  PLAYROOM_03_CAPACITY AS PLAYROOM_03_CAPACITY,
  PLAYROOM_04_CAPACITY AS PLAYROOM_04_CAPACITY,
  PLAYROOM_05_CAPACITY AS PLAYROOM_05_CAPACITY,
  PLAYROOM_06_CAPACITY AS PLAYROOM_06_CAPACITY,
  PLAYROOM_07_CAPACITY AS PLAYROOM_07_CAPACITY,
  PLAYROOM_08_CAPACITY AS PLAYROOM_08_CAPACITY,
  PLAYROOM_09_CAPACITY AS PLAYROOM_09_CAPACITY,
  PLAYROOM_10_CAPACITY AS PLAYROOM_10_CAPACITY
FROM
  UDH_PS2_HTL_PLAYROOM_CAPACITY"""

df_0 = spark.sql(query_0)

df_0.createOrReplaceTempView("Shortcut_to_UDH_PS2_HTL_PLAYROOM_CAPACITY_0")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_UDH_PS2_HTL_PLAYROOM_CAPACITY_1


query_1 = f"""SELECT
  STORE_NBR AS STORE_NBR,
  EFF_DT AS EFF_DT,
  END_DT AS END_DT,
  DAY_OF_WEEK AS DAY_OF_WEEK,
  NORMAL_HRS_ROOM_QTY AS NORMAL_HRS_ROOM_QTY,
  PLAYROOM_01_CAPACITY AS PLAYROOM_01_CAPACITY,
  PLAYROOM_02_CAPACITY AS PLAYROOM_02_CAPACITY,
  PLAYROOM_03_CAPACITY AS PLAYROOM_03_CAPACITY,
  PLAYROOM_04_CAPACITY AS PLAYROOM_04_CAPACITY,
  PLAYROOM_05_CAPACITY AS PLAYROOM_05_CAPACITY,
  PLAYROOM_06_CAPACITY AS PLAYROOM_06_CAPACITY,
  PLAYROOM_07_CAPACITY AS PLAYROOM_07_CAPACITY,
  PLAYROOM_08_CAPACITY AS PLAYROOM_08_CAPACITY,
  PLAYROOM_09_CAPACITY AS PLAYROOM_09_CAPACITY,
  PLAYROOM_10_CAPACITY AS PLAYROOM_10_CAPACITY,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_UDH_PS2_HTL_PLAYROOM_CAPACITY_0"""

df_1 = spark.sql(query_1)

df_1.createOrReplaceTempView("SQ_Shortcut_to_UDH_PS2_HTL_PLAYROOM_CAPACITY_1")

# COMMAND ----------
# DBTITLE 1, LKP_SITE_PROFILE_2


query_2 = f"""SELECT
  SP.LOCATION_ID AS LOCATION_ID,
  SStUPHPC1.STORE_NBR AS IN_STORE_NBR,
  SStUPHPC1.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  SQ_Shortcut_to_UDH_PS2_HTL_PLAYROOM_CAPACITY_1 SStUPHPC1
  LEFT JOIN SITE_PROFILE SP ON SP.STORE_NBR = SStUPHPC1.STORE_NBR"""

df_2 = spark.sql(query_2)

df_2.createOrReplaceTempView("LKP_SITE_PROFILE_2")

# COMMAND ----------
# DBTITLE 1, EXP_RemoveNulls_3


query_3 = f"""SELECT
  LSP2.LOCATION_ID AS LOCATION_ID,
  TO_INTEGER(LSP2.LOCATION_ID) AS INT_LOCATION_ID,
  SStUPHPC1.STORE_NBR AS STORE_NBR,
  SStUPHPC1.EFF_DT AS EFF_DT,
  SStUPHPC1.END_DT AS END_DT,
  IFF(
    ISNULL(SStUPHPC1.END_DT),
    TO_DATE('20991231', 'YYYYMMDD'),
    SStUPHPC1.END_DT
  ) AS END_DT_NN,
  SStUPHPC1.DAY_OF_WEEK AS DAY_OF_WEEK,
  SStUPHPC1.NORMAL_HRS_ROOM_QTY AS NORMAL_HRS_ROOM_QTY,
  SStUPHPC1.PLAYROOM_01_CAPACITY AS PLAYROOM_01_CAPACITY,
  SStUPHPC1.PLAYROOM_02_CAPACITY AS PLAYROOM_02_CAPACITY,
  SStUPHPC1.PLAYROOM_03_CAPACITY AS PLAYROOM_03_CAPACITY,
  SStUPHPC1.PLAYROOM_04_CAPACITY AS PLAYROOM_04_CAPACITY,
  SStUPHPC1.PLAYROOM_05_CAPACITY AS PLAYROOM_05_CAPACITY,
  SStUPHPC1.PLAYROOM_06_CAPACITY AS PLAYROOM_06_CAPACITY,
  SStUPHPC1.PLAYROOM_07_CAPACITY AS PLAYROOM_07_CAPACITY,
  SStUPHPC1.PLAYROOM_08_CAPACITY AS PLAYROOM_08_CAPACITY,
  SStUPHPC1.PLAYROOM_09_CAPACITY AS PLAYROOM_09_CAPACITY,
  SStUPHPC1.PLAYROOM_10_CAPACITY AS PLAYROOM_10_CAPACITY,
  IFF(
    ISNULL(SStUPHPC1.PLAYROOM_01_CAPACITY),
    0,
    SStUPHPC1.PLAYROOM_01_CAPACITY
  ) AS PLAYROOM_01_CAPACITY_NN,
  IFF(
    ISNULL(SStUPHPC1.PLAYROOM_02_CAPACITY),
    0,
    SStUPHPC1.PLAYROOM_02_CAPACITY
  ) AS PLAYROOM_02_CAPACITY_NN,
  IFF(
    ISNULL(SStUPHPC1.PLAYROOM_03_CAPACITY),
    0,
    SStUPHPC1.PLAYROOM_03_CAPACITY
  ) AS PLAYROOM_03_CAPACITY_NN,
  IFF(
    ISNULL(SStUPHPC1.PLAYROOM_04_CAPACITY),
    0,
    SStUPHPC1.PLAYROOM_04_CAPACITY
  ) AS PLAYROOM_04_CAPACITY_NN,
  IFF(
    ISNULL(SStUPHPC1.PLAYROOM_05_CAPACITY),
    0,
    SStUPHPC1.PLAYROOM_05_CAPACITY
  ) AS PLAYROOM_05_CAPACITY_NN,
  IFF(
    ISNULL(SStUPHPC1.PLAYROOM_06_CAPACITY),
    0,
    SStUPHPC1.PLAYROOM_06_CAPACITY
  ) AS PLAYROOM_06_CAPACITY_NN,
  IFF(
    ISNULL(SStUPHPC1.PLAYROOM_07_CAPACITY),
    0,
    SStUPHPC1.PLAYROOM_07_CAPACITY
  ) AS PLAYROOM_07_CAPACITY_NN,
  IFF(
    ISNULL(SStUPHPC1.PLAYROOM_08_CAPACITY),
    0,
    SStUPHPC1.PLAYROOM_08_CAPACITY
  ) AS PLAYROOM_08_CAPACITY_NN,
  IFF(
    ISNULL(SStUPHPC1.PLAYROOM_09_CAPACITY),
    0,
    SStUPHPC1.PLAYROOM_09_CAPACITY
  ) AS PLAYROOM_09_CAPACITY_NN,
  IFF(
    ISNULL(SStUPHPC1.PLAYROOM_10_CAPACITY),
    0,
    SStUPHPC1.PLAYROOM_10_CAPACITY
  ) AS PLAYROOM_10_CAPACITY_NN,
  now() AS LOAD_TSTMP,
  LSP2.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  LKP_SITE_PROFILE_2 LSP2
  INNER JOIN SQ_Shortcut_to_UDH_PS2_HTL_PLAYROOM_CAPACITY_1 SStUPHPC1 ON LSP2.Monotonically_Increasing_Id = SStUPHPC1.Monotonically_Increasing_Id"""

df_3 = spark.sql(query_3)

df_3.createOrReplaceTempView("EXP_RemoveNulls_3")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_SITE_PROFILE_4


query_4 = f"""SELECT
  LOCATION_ID AS LOCATION_ID,
  LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
  STORE_NBR AS STORE_NBR,
  STORE_NAME AS STORE_NAME,
  STORE_TYPE_ID AS STORE_TYPE_ID,
  STORE_OPEN_CLOSE_FLAG AS STORE_OPEN_CLOSE_FLAG,
  COMPANY_ID AS COMPANY_ID,
  REGION_ID AS REGION_ID,
  DISTRICT_ID AS DISTRICT_ID,
  PRICE_ZONE_ID AS PRICE_ZONE_ID,
  PRICE_AD_ZONE_ID AS PRICE_AD_ZONE_ID,
  REPL_DC_NBR AS REPL_DC_NBR,
  REPL_FISH_DC_NBR AS REPL_FISH_DC_NBR,
  REPL_FWD_DC_NBR AS REPL_FWD_DC_NBR,
  SQ_FEET_RETAIL AS SQ_FEET_RETAIL,
  SQ_FEET_TOTAL AS SQ_FEET_TOTAL,
  SITE_ADDRESS AS SITE_ADDRESS,
  SITE_CITY AS SITE_CITY,
  STATE_CD AS STATE_CD,
  COUNTRY_CD AS COUNTRY_CD,
  POSTAL_CD AS POSTAL_CD,
  SITE_MAIN_TELE_NO AS SITE_MAIN_TELE_NO,
  SITE_GROOM_TELE_NO AS SITE_GROOM_TELE_NO,
  SITE_EMAIL_ADDRESS AS SITE_EMAIL_ADDRESS,
  SITE_SALES_FLAG AS SITE_SALES_FLAG,
  EQUINE_MERCH_ID AS EQUINE_MERCH_ID,
  EQUINE_SITE_ID AS EQUINE_SITE_ID,
  EQUINE_SITE_OPEN_DT AS EQUINE_SITE_OPEN_DT,
  GEO_LATITUDE_NBR AS GEO_LATITUDE_NBR,
  GEO_LONGITUDE_NBR AS GEO_LONGITUDE_NBR,
  PETSMART_DMA_CD AS PETSMART_DMA_CD,
  LOYALTY_PGM_TYPE_ID AS LOYALTY_PGM_TYPE_ID,
  LOYALTY_PGM_STATUS_ID AS LOYALTY_PGM_STATUS_ID,
  LOYALTY_PGM_START_DT AS LOYALTY_PGM_START_DT,
  LOYALTY_PGM_CHANGE_DT AS LOYALTY_PGM_CHANGE_DT,
  BP_COMPANY_NBR AS BP_COMPANY_NBR,
  BP_GL_ACCT AS BP_GL_ACCT,
  TP_LOC_FLAG AS TP_LOC_FLAG,
  TP_ACTIVE_CNT AS TP_ACTIVE_CNT,
  PROMO_LABEL_CD AS PROMO_LABEL_CD,
  PARENT_LOCATION_ID AS PARENT_LOCATION_ID,
  LOCATION_NBR AS LOCATION_NBR,
  TIME_ZONE_ID AS TIME_ZONE_ID,
  DELV_SERVICE_CLASS_ID AS DELV_SERVICE_CLASS_ID,
  PICK_SERVICE_CLASS_ID AS PICK_SERVICE_CLASS_ID,
  SITE_LOGIN_ID AS SITE_LOGIN_ID,
  SITE_MANAGER_ID AS SITE_MANAGER_ID,
  SITE_OPEN_YRS_AMT AS SITE_OPEN_YRS_AMT,
  HOTEL_FLAG AS HOTEL_FLAG,
  DAYCAMP_FLAG AS DAYCAMP_FLAG,
  VET_FLAG AS VET_FLAG,
  DIST_MGR_NAME AS DIST_MGR_NAME,
  DIST_SVC_MGR_NAME AS DIST_SVC_MGR_NAME,
  REGION_VP_NAME AS REGION_VP_NAME,
  REGION_TRAINER_NAME AS REGION_TRAINER_NAME,
  ASSET_PROTECT_NAME AS ASSET_PROTECT_NAME,
  SITE_COUNTY AS SITE_COUNTY,
  SITE_FAX_NO AS SITE_FAX_NO,
  SFT_OPEN_DT AS SFT_OPEN_DT,
  DM_EMAIL_ADDRESS AS DM_EMAIL_ADDRESS,
  DSM_EMAIL_ADDRESS AS DSM_EMAIL_ADDRESS,
  RVP_EMAIL_ADDRESS AS RVP_EMAIL_ADDRESS,
  TRADE_AREA AS TRADE_AREA,
  FDLPS_NAME AS FDLPS_NAME,
  FDLPS_EMAIL AS FDLPS_EMAIL,
  OVERSITE_MGR_NAME AS OVERSITE_MGR_NAME,
  OVERSITE_MGR_EMAIL AS OVERSITE_MGR_EMAIL,
  SAFETY_DIRECTOR_NAME AS SAFETY_DIRECTOR_NAME,
  SAFETY_DIRECTOR_EMAIL AS SAFETY_DIRECTOR_EMAIL,
  RETAIL_MANAGER_SAFETY_NAME AS RETAIL_MANAGER_SAFETY_NAME,
  RETAIL_MANAGER_SAFETY_EMAIL AS RETAIL_MANAGER_SAFETY_EMAIL,
  AREA_DIRECTOR_NAME AS AREA_DIRECTOR_NAME,
  AREA_DIRECTOR_EMAIL AS AREA_DIRECTOR_EMAIL,
  DC_GENERAL_MANAGER_NAME AS DC_GENERAL_MANAGER_NAME,
  DC_GENERAL_MANAGER_EMAIL AS DC_GENERAL_MANAGER_EMAIL,
  ASST_DC_GENERAL_MANAGER_NAME1 AS ASST_DC_GENERAL_MANAGER_NAME1,
  ASST_DC_GENERAL_MANAGER_EMAIL1 AS ASST_DC_GENERAL_MANAGER_EMAIL1,
  ASST_DC_GENERAL_MANAGER_NAME2 AS ASST_DC_GENERAL_MANAGER_NAME2,
  ASST_DC_GENERAL_MANAGER_EMAIL2 AS ASST_DC_GENERAL_MANAGER_EMAIL2,
  REGIONAL_DC_SAFETY_MGR_NAME AS REGIONAL_DC_SAFETY_MGR_NAME,
  REGIONAL_DC_SAFETY_MGR_EMAIL AS REGIONAL_DC_SAFETY_MGR_EMAIL,
  DC_PEOPLE_SUPERVISOR_NAME AS DC_PEOPLE_SUPERVISOR_NAME,
  DC_PEOPLE_SUPERVISOR_EMAIL AS DC_PEOPLE_SUPERVISOR_EMAIL,
  PEOPLE_MANAGER_NAME AS PEOPLE_MANAGER_NAME,
  PEOPLE_MANAGER_EMAIL AS PEOPLE_MANAGER_EMAIL,
  ASSET_PROT_DIR_NAME AS ASSET_PROT_DIR_NAME,
  ASSET_PROT_DIR_EMAIL AS ASSET_PROT_DIR_EMAIL,
  SR_REG_ASSET_PROT_MGR_NAME AS SR_REG_ASSET_PROT_MGR_NAME,
  SR_REG_ASSET_PROT_MGR_EMAIL AS SR_REG_ASSET_PROT_MGR_EMAIL,
  REG_ASSET_PROT_MGR_NAME AS REG_ASSET_PROT_MGR_NAME,
  REG_ASSET_PROT_MGR_EMAIL AS REG_ASSET_PROT_MGR_EMAIL,
  ASSET_PROTECT_EMAIL AS ASSET_PROTECT_EMAIL,
  TP_START_DT AS TP_START_DT,
  OPEN_DT AS OPEN_DT,
  GR_OPEN_DT AS GR_OPEN_DT,
  CLOSE_DT AS CLOSE_DT,
  HOTEL_OPEN_DT AS HOTEL_OPEN_DT,
  ADD_DT AS ADD_DT,
  DELETE_DT AS DELETE_DT,
  UPDATE_DT AS UPDATE_DT,
  LOAD_DT AS LOAD_DT
FROM
  SITE_PROFILE"""

df_4 = spark.sql(query_4)

df_4.createOrReplaceTempView("Shortcut_to_SITE_PROFILE_4")

# COMMAND ----------
# DBTITLE 1, PS2_HTL_PLAYROOM_CAPACITY


spark.sql("""INSERT INTO
  PS2_HTL_PLAYROOM_CAPACITY
SELECT
  LOCATION_ID AS LOCATION_ID,
  DAY_OF_WEEK AS DAY_OF_WEEK,
  EFF_DT AS PLAYROOM_CAP_EFF_DT,
  END_DT AS PLAYROOM_CAP_END_DT,
  STORE_NBR AS STORE_NBR,
  NORMAL_HRS_ROOM_QTY AS NORMAL_HRS_ROOM_QTY,
  PLAYROOM_01_CAPACITY_NN AS PLAYROOM_01_CAPACITY,
  PLAYROOM_02_CAPACITY_NN AS PLAYROOM_02_CAPACITY,
  PLAYROOM_03_CAPACITY_NN AS PLAYROOM_03_CAPACITY,
  PLAYROOM_04_CAPACITY_NN AS PLAYROOM_04_CAPACITY,
  PLAYROOM_05_CAPACITY_NN AS PLAYROOM_05_CAPACITY,
  PLAYROOM_06_CAPACITY_NN AS PLAYROOM_06_CAPACITY,
  PLAYROOM_07_CAPACITY_NN AS PLAYROOM_07_CAPACITY,
  PLAYROOM_08_CAPACITY_NN AS PLAYROOM_08_CAPACITY,
  PLAYROOM_09_CAPACITY_NN AS PLAYROOM_09_CAPACITY,
  PLAYROOM_10_CAPACITY_NN AS PLAYROOM_10_CAPACITY,
  LOAD_TSTMP AS LOAD_TSTMP
FROM
  EXP_RemoveNulls_3""")

# COMMAND ----------
#Post session variable updation
updateVariable(postVariableAssignment, variablesTableName, mainWorkflowId, parentName, "m_ps2_htl_PlayroomCapacity")

# COMMAND ----------
#Update Mapping Variables in database.
persistVariables(variablesTableName, "m_ps2_htl_PlayroomCapacity", mainWorkflowId, parentName)
