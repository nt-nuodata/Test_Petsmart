# Databricks notebook source
# MAGIC %run "./udf_informatica"

# COMMAND ----------


from pyspark.sql.types import *

spark.sql("use DELTA_TRAINING")
spark.sql("set spark.sql.legacy.timeParserPolicy = LEGACY")

# COMMAND ----------
%run ./MappingUtility

# COMMAND ----------
mainWorkflowId = dbutils.widgets.get("mainWorkflowId")
mainWorkflowRunId = dbutils.widgets.get("mainWorkflowRunId")
parentName = dbutils.widgets.get("parentName")
preVariableAssignment = dbutils.widgets.get("preVariableAssignment")
postVariableAssignment = dbutils.widgets.get("postVariableAssignment")
truncTargetTableOptions = dbutils.widgets.get("truncTargetTableOptions")
variablesTableName = dbutils.widgets.get("variablesTableName")

# COMMAND ----------
#Truncate Target Tables
truncateTargetTables(truncTargetTableOptions)

# COMMAND ----------
#Pre presession variable updation
updateVariable(preVariableAssignment, variablesTableName, mainWorkflowId, parentName, "m_ps2_ca_htl_earn_hrs_pre_DEFAULT")

# COMMAND ----------
fetchAndCreateVariables(parentName,"m_ps2_ca_htl_earn_hrs_pre_DEFAULT", variablesTableName, mainWorkflowId)

# COMMAND ----------
# DBTITLE 1, Shortcut_to_PETSHOTEL_ACCRUAL_0


query_0 = f"""SELECT
  DAY_DT AS DAY_DT,
  ACCRUAL_DT AS ACCRUAL_DT,
  LOCATION_ID AS LOCATION_ID,
  STORE_NBR AS STORE_NBR,
  TP_INVOICE_NBR AS TP_INVOICE_NBR,
  SERVICE_START_DT AS SERVICE_START_DT,
  SERVICE_END_DT AS SERVICE_END_DT,
  LENGTH_OF_STAY AS LENGTH_OF_STAY,
  TP_EXTENDED_PRICE AS TP_EXTENDED_PRICE,
  PETCOUNT AS PETCOUNT,
  ACCRUAL_AMT AS ACCRUAL_AMT,
  EXCH_RATE_PCNT AS EXCH_RATE_PCNT,
  WEEK_DT AS WEEK_DT,
  FISCAL_YR AS FISCAL_YR,
  FISCAL_MO AS FISCAL_MO,
  FISCAL_WK AS FISCAL_WK,
  LOAD_DT AS LOAD_DT
FROM
  PETSHOTEL_ACCRUAL"""

df_0 = spark.sql(query_0)

df_0.createOrReplaceTempView("Shortcut_to_PETSHOTEL_ACCRUAL_0")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_PETSHOTEL_ACCRUAL_1


query_1 = f"""SELECT
  WEEK_DT AS WEEK_DT,
  LOCATION_ID AS LOCATION_ID,
  STORE_NBR AS STORE_NBR,
  ACCRUAL_AMT AS ACCRUAL_AMT,
  EXCH_RATE_PCNT AS EXCH_RATE_PCNT,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_PETSHOTEL_ACCRUAL_0
WHERE
  WEEK_DT < CURRENT_DATE - (DATE_PART('DOW', CURRENT_DATE - 1)) + 1
  and WEEK_DT > TO_DATE('2011-01-01', 'YYYY-MM-DD')"""

df_1 = spark.sql(query_1)

df_1.createOrReplaceTempView("SQ_Shortcut_to_PETSHOTEL_ACCRUAL_1")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_PS_PAYROLL_CALENDAR_2


query_2 = f"""SELECT
  CHECK_DT AS CHECK_DT,
  PS_TAX_COMPANY_CD AS PS_TAX_COMPANY_CD,
  PAY_PERIOD_PARAMETER AS PAY_PERIOD_PARAMETER,
  PERIOD_START_DT AS PERIOD_START_DT,
  PERIOD_END_DT AS PERIOD_END_DT
FROM
  PS_PAYROLL_CALENDAR"""

df_2 = spark.sql(query_2)

df_2.createOrReplaceTempView("Shortcut_to_PS_PAYROLL_CALENDAR_2")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_PS_PAYROLL_CALENDAR_3


query_3 = f"""SELECT
  DISTINCT CHECK_DT AS CHECK_DT,
  PS_TAX_COMPANY_CD AS PS_TAX_COMPANY_CD,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_PS_PAYROLL_CALENDAR_2
WHERE
  PS_TAX_COMPANY_CD = 'NCJ'
  AND CHECK_DT > TO_DATE('2011-01-01', 'YYYY-MM-DD')"""

df_3 = spark.sql(query_3)

df_3.createOrReplaceTempView("SQ_Shortcut_to_PS_PAYROLL_CALENDAR_3")

# COMMAND ----------
# DBTITLE 1, EXPTRANS_4


query_4 = f"""SELECT
  ADD_TO_DATE(
    CHECK_DT,
    'DD',
    - TO_INTEGER(TO_char(CHECK_DT, 'D')) + 1
  ) AS WEEK_DT,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  SQ_Shortcut_to_PS_PAYROLL_CALENDAR_3"""

df_4 = spark.sql(query_4)

df_4.createOrReplaceTempView("EXPTRANS_4")

# COMMAND ----------
# DBTITLE 1, Shortcut_to_SITE_PROFILE_5


query_5 = f"""SELECT
  LOCATION_ID AS LOCATION_ID,
  LOCATION_TYPE_ID AS LOCATION_TYPE_ID,
  STORE_NBR AS STORE_NBR,
  STORE_NAME AS STORE_NAME,
  STORE_TYPE_ID AS STORE_TYPE_ID,
  STORE_OPEN_CLOSE_FLAG AS STORE_OPEN_CLOSE_FLAG,
  COMPANY_ID AS COMPANY_ID,
  REGION_ID AS REGION_ID,
  DISTRICT_ID AS DISTRICT_ID,
  PRICE_ZONE_ID AS PRICE_ZONE_ID,
  PRICE_AD_ZONE_ID AS PRICE_AD_ZONE_ID,
  REPL_DC_NBR AS REPL_DC_NBR,
  REPL_FISH_DC_NBR AS REPL_FISH_DC_NBR,
  REPL_FWD_DC_NBR AS REPL_FWD_DC_NBR,
  SQ_FEET_RETAIL AS SQ_FEET_RETAIL,
  SQ_FEET_TOTAL AS SQ_FEET_TOTAL,
  SITE_ADDRESS AS SITE_ADDRESS,
  SITE_CITY AS SITE_CITY,
  STATE_CD AS STATE_CD,
  COUNTRY_CD AS COUNTRY_CD,
  POSTAL_CD AS POSTAL_CD,
  SITE_MAIN_TELE_NO AS SITE_MAIN_TELE_NO,
  SITE_GROOM_TELE_NO AS SITE_GROOM_TELE_NO,
  SITE_EMAIL_ADDRESS AS SITE_EMAIL_ADDRESS,
  SITE_SALES_FLAG AS SITE_SALES_FLAG,
  EQUINE_MERCH_ID AS EQUINE_MERCH_ID,
  EQUINE_SITE_ID AS EQUINE_SITE_ID,
  EQUINE_SITE_OPEN_DT AS EQUINE_SITE_OPEN_DT,
  GEO_LATITUDE_NBR AS GEO_LATITUDE_NBR,
  GEO_LONGITUDE_NBR AS GEO_LONGITUDE_NBR,
  PETSMART_DMA_CD AS PETSMART_DMA_CD,
  LOYALTY_PGM_TYPE_ID AS LOYALTY_PGM_TYPE_ID,
  LOYALTY_PGM_STATUS_ID AS LOYALTY_PGM_STATUS_ID,
  LOYALTY_PGM_START_DT AS LOYALTY_PGM_START_DT,
  LOYALTY_PGM_CHANGE_DT AS LOYALTY_PGM_CHANGE_DT,
  BP_COMPANY_NBR AS BP_COMPANY_NBR,
  BP_GL_ACCT AS BP_GL_ACCT,
  TP_LOC_FLAG AS TP_LOC_FLAG,
  TP_ACTIVE_CNT AS TP_ACTIVE_CNT,
  PROMO_LABEL_CD AS PROMO_LABEL_CD,
  PARENT_LOCATION_ID AS PARENT_LOCATION_ID,
  LOCATION_NBR AS LOCATION_NBR,
  TIME_ZONE_ID AS TIME_ZONE_ID,
  DELV_SERVICE_CLASS_ID AS DELV_SERVICE_CLASS_ID,
  PICK_SERVICE_CLASS_ID AS PICK_SERVICE_CLASS_ID,
  SITE_LOGIN_ID AS SITE_LOGIN_ID,
  SITE_MANAGER_ID AS SITE_MANAGER_ID,
  SITE_OPEN_YRS_AMT AS SITE_OPEN_YRS_AMT,
  HOTEL_FLAG AS HOTEL_FLAG,
  DAYCAMP_FLAG AS DAYCAMP_FLAG,
  VET_FLAG AS VET_FLAG,
  DIST_MGR_NAME AS DIST_MGR_NAME,
  DIST_SVC_MGR_NAME AS DIST_SVC_MGR_NAME,
  REGION_VP_NAME AS REGION_VP_NAME,
  REGION_TRAINER_NAME AS REGION_TRAINER_NAME,
  ASSET_PROTECT_NAME AS ASSET_PROTECT_NAME,
  SITE_COUNTY AS SITE_COUNTY,
  SITE_FAX_NO AS SITE_FAX_NO,
  SFT_OPEN_DT AS SFT_OPEN_DT,
  DM_EMAIL_ADDRESS AS DM_EMAIL_ADDRESS,
  DSM_EMAIL_ADDRESS AS DSM_EMAIL_ADDRESS,
  RVP_EMAIL_ADDRESS AS RVP_EMAIL_ADDRESS,
  TRADE_AREA AS TRADE_AREA,
  FDLPS_NAME AS FDLPS_NAME,
  FDLPS_EMAIL AS FDLPS_EMAIL,
  OVERSITE_MGR_NAME AS OVERSITE_MGR_NAME,
  OVERSITE_MGR_EMAIL AS OVERSITE_MGR_EMAIL,
  SAFETY_DIRECTOR_NAME AS SAFETY_DIRECTOR_NAME,
  SAFETY_DIRECTOR_EMAIL AS SAFETY_DIRECTOR_EMAIL,
  RETAIL_MANAGER_SAFETY_NAME AS RETAIL_MANAGER_SAFETY_NAME,
  RETAIL_MANAGER_SAFETY_EMAIL AS RETAIL_MANAGER_SAFETY_EMAIL,
  AREA_DIRECTOR_NAME AS AREA_DIRECTOR_NAME,
  AREA_DIRECTOR_EMAIL AS AREA_DIRECTOR_EMAIL,
  DC_GENERAL_MANAGER_NAME AS DC_GENERAL_MANAGER_NAME,
  DC_GENERAL_MANAGER_EMAIL AS DC_GENERAL_MANAGER_EMAIL,
  ASST_DC_GENERAL_MANAGER_NAME1 AS ASST_DC_GENERAL_MANAGER_NAME1,
  ASST_DC_GENERAL_MANAGER_EMAIL1 AS ASST_DC_GENERAL_MANAGER_EMAIL1,
  ASST_DC_GENERAL_MANAGER_NAME2 AS ASST_DC_GENERAL_MANAGER_NAME2,
  ASST_DC_GENERAL_MANAGER_EMAIL2 AS ASST_DC_GENERAL_MANAGER_EMAIL2,
  REGIONAL_DC_SAFETY_MGR_NAME AS REGIONAL_DC_SAFETY_MGR_NAME,
  REGIONAL_DC_SAFETY_MGR_EMAIL AS REGIONAL_DC_SAFETY_MGR_EMAIL,
  DC_PEOPLE_SUPERVISOR_NAME AS DC_PEOPLE_SUPERVISOR_NAME,
  DC_PEOPLE_SUPERVISOR_EMAIL AS DC_PEOPLE_SUPERVISOR_EMAIL,
  PEOPLE_MANAGER_NAME AS PEOPLE_MANAGER_NAME,
  PEOPLE_MANAGER_EMAIL AS PEOPLE_MANAGER_EMAIL,
  ASSET_PROT_DIR_NAME AS ASSET_PROT_DIR_NAME,
  ASSET_PROT_DIR_EMAIL AS ASSET_PROT_DIR_EMAIL,
  SR_REG_ASSET_PROT_MGR_NAME AS SR_REG_ASSET_PROT_MGR_NAME,
  SR_REG_ASSET_PROT_MGR_EMAIL AS SR_REG_ASSET_PROT_MGR_EMAIL,
  REG_ASSET_PROT_MGR_NAME AS REG_ASSET_PROT_MGR_NAME,
  REG_ASSET_PROT_MGR_EMAIL AS REG_ASSET_PROT_MGR_EMAIL,
  ASSET_PROTECT_EMAIL AS ASSET_PROTECT_EMAIL,
  TP_START_DT AS TP_START_DT,
  OPEN_DT AS OPEN_DT,
  GR_OPEN_DT AS GR_OPEN_DT,
  CLOSE_DT AS CLOSE_DT,
  HOTEL_OPEN_DT AS HOTEL_OPEN_DT,
  ADD_DT AS ADD_DT,
  DELETE_DT AS DELETE_DT,
  UPDATE_DT AS UPDATE_DT,
  LOAD_DT AS LOAD_DT
FROM
  SITE_PROFILE"""

df_5 = spark.sql(query_5)

df_5.createOrReplaceTempView("Shortcut_to_SITE_PROFILE_5")

# COMMAND ----------
# DBTITLE 1, SQ_Shortcut_to_SITE_PROFILE_6


query_6 = f"""SELECT
  LOCATION_ID AS LOCATION_ID,
  STATE_CD AS STATE_CD,
  COUNTRY_CD AS COUNTRY_CD,
  monotonically_increasing_id() AS Monotonically_Increasing_Id
FROM
  Shortcut_to_SITE_PROFILE_5
WHERE
  COUNTRY_CD = 'CA'"""

df_6 = spark.sql(query_6)

df_6.createOrReplaceTempView("SQ_Shortcut_to_SITE_PROFILE_6")

# COMMAND ----------
# DBTITLE 1, JNRTRANS_7


query_7 = f"""SELECT
  DETAIL.WEEK_DT AS WEEK_DT,
  DETAIL.LOCATION_ID AS LOCATION_ID,
  DETAIL.STORE_NBR AS STORE_NBR,
  DETAIL.ACCRUAL_AMT AS ACCRUAL_AMT,
  DETAIL.EXCH_RATE_PCNT AS EXCH_RATE_PCNT,
  MASTER.LOCATION_ID AS LOCATION_ID_sp,
  MASTER.STATE_CD AS STATE_CD_sp,
  MASTER.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  SQ_Shortcut_to_SITE_PROFILE_6 MASTER
  INNER JOIN SQ_Shortcut_to_PETSHOTEL_ACCRUAL_1 DETAIL ON MASTER.LOCATION_ID = DETAIL.LOCATION_ID"""

df_7 = spark.sql(query_7)

df_7.createOrReplaceTempView("JNRTRANS_7")

# COMMAND ----------
# DBTITLE 1, AGGTRANS_8


query_8 = f"""SELECT
  WEEK_DT AS WEEK_DT,
  LOCATION_ID AS LOCATION_ID,
  STORE_NBR AS STORE_NBR,
  STATE_CD_sp AS STATE_CD_sp,
  'HOTEL' AS BUSN_TYPE,
  MAX(EXCH_RATE_PCNT) AS EXCH_RATE_PCNT,
  SUM(ACCRUAL_AMT / EXCH_RATE_PCNT) AS TTL_HOTEL_SALES,
  last(Monotonically_Increasing_Id) AS Monotonically_Increasing_Id
FROM
  JNRTRANS_7
GROUP BY
  WEEK_DT,
  LOCATION_ID,
  STATE_CD_sp"""

df_8 = spark.sql(query_8)

df_8.createOrReplaceTempView("AGGTRANS_8")

# COMMAND ----------
# DBTITLE 1, JNRTRANS1_9


query_9 = f"""SELECT
  MASTER.WEEK_DT AS WEEK_DT,
  DETAIL.WEEK_DT AS CHECK_DT,
  MASTER.LOCATION_ID AS LOCATION_ID,
  MASTER.STORE_NBR AS STORE_NBR,
  MASTER.STATE_CD_sp AS STATE_CD,
  MASTER.BUSN_TYPE AS BUSN_TYPE,
  MASTER.EXCH_RATE_PCNT AS EXCH_RATE_PCNT,
  MASTER.TTL_HOTEL_SALES AS TTL_HOTEL_SALES,
  MASTER.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  AGGTRANS_8 MASTER
  LEFT JOIN EXPTRANS_4 DETAIL ON MASTER.WEEK_DT = DETAIL.WEEK_DT"""

df_9 = spark.sql(query_9)

df_9.createOrReplaceTempView("JNRTRANS1_9")

# COMMAND ----------
# DBTITLE 1, EXPTRANS2_10


query_10 = f"""SELECT
  WEEK_DT AS WEEK_DT,
  CHECK_DT AS CHECK_DT,
  LOCATION_ID AS LOCATION_ID,
  TO_CHAR(STORE_NBR) AS STORE_NBR,
  STATE_CD AS STATE_CD,
  BUSN_TYPE AS BUSN_TYPE,
  EXCH_RATE_PCNT AS EXCH_RATE_PCNT,
  TTL_HOTEL_SALES AS TTL_HOTEL_SALES,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  JNRTRANS1_9"""

df_10 = spark.sql(query_10)

df_10.createOrReplaceTempView("EXPTRANS2_10")

# COMMAND ----------
# DBTITLE 1, LKPTRANS_11


query_11 = f"""SELECT
  PLM.START_DT AS START_DT,
  PLM.END_DT AS END_DT,
  PLM.STORE_NBR AS STORE_NBR,
  PLM.BUSINESS_AREA AS BUSINESS_AREA,
  PLM.L_RANGE AS L_RANGE,
  PLM.H_RANGE AS H_RANGE,
  PLM.VARIABLE_FACTOR AS VARIABLE_FACTOR,
  PLM.FIXED_HOURS AS FIXED_HOURS,
  E1.WEEK_DT AS WEEK_DT,
  E1.BUSN_TYPE AS BUSN_TYPE,
  E1.TTL_HOTEL_SALES AS TTL_HOTEL_SALES,
  E1.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  EXPTRANS2_10 E1
  LEFT JOIN PS2_LABOR_MATRIX PLM ON PLM.START_DT <= E1.WEEK_DT
  AND PLM.END_DT >= E1.WEEK_DT
  AND PLM.BUSINESS_AREA = E1.BUSN_TYPE
  AND PLM.L_RANGE < E1.TTL_HOTEL_SALES
  AND PLM.H_RANGE >= E1.TTL_HOTEL_SALES"""

df_11 = spark.sql(query_11)

df_11.createOrReplaceTempView("LKPTRANS_11")

# COMMAND ----------
# DBTITLE 1, FILTRANS1_12


query_12 = f"""SELECT
  E1.WEEK_DT AS WEEK_DT,
  E1.CHECK_DT AS CHECK_DT,
  E1.LOCATION_ID AS LOCATION_ID,
  E1.STORE_NBR AS STORE_NBR,
  E1.STATE_CD AS STATE_CD,
  E1.BUSN_TYPE AS BUSN_TYPE,
  E1.EXCH_RATE_PCNT AS EXCH_RATE_PCNT,
  E1.TTL_HOTEL_SALES AS TTL_HOTEL_SALES,
  L1.VARIABLE_FACTOR AS VARIABLE_FACTOR,
  L1.FIXED_HOURS AS FIXED_HOURS,
  E1.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  EXPTRANS2_10 E1
  INNER JOIN LKPTRANS_11 L1 ON E1.Monotonically_Increasing_Id = L1.Monotonically_Increasing_Id
WHERE
  E1.WEEK_DT > TO_DATE('2010-12-31', 'YYYY-MM-DD')"""

df_12 = spark.sql(query_12)

df_12.createOrReplaceTempView("FILTRANS1_12")

# COMMAND ----------
# DBTITLE 1, LKPTRANS1_13


query_13 = f"""SELECT
  PLM.START_DT AS START_DT,
  PLM.END_DT AS END_DT,
  PLM.STORE_NBR AS STORE_NBR,
  PLM.BUSINESS_AREA AS BUSINESS_AREA,
  PLM.L_RANGE AS L_RANGE,
  PLM.H_RANGE AS H_RANGE,
  PLM.VARIABLE_FACTOR AS VARIABLE_FACTOR,
  PLM.FIXED_HOURS AS FIXED_HOURS,
  F1.WEEK_DT AS WEEK_DT,
  F1.STORE_NBR AS STORE_NBR1,
  F1.BUSN_TYPE AS BUSN_TYPE,
  F1.TTL_HOTEL_SALES AS TTL_HOTEL_SALES,
  F1.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  FILTRANS1_12 F1
  LEFT JOIN PS2_LABOR_MATRIX PLM ON PLM.START_DT <= F1.WEEK_DT
  AND PLM.END_DT >= F1.WEEK_DT
  AND PLM.STORE_NBR = F1.STORE_NBR
  AND PLM.BUSINESS_AREA = F1.BUSN_TYPE
  AND PLM.L_RANGE <= F1.TTL_HOTEL_SALES
  AND PLM.H_RANGE > F1.TTL_HOTEL_SALES"""

df_13 = spark.sql(query_13)

df_13.createOrReplaceTempView("LKPTRANS1_13")

# COMMAND ----------
# DBTITLE 1, FILTRANS_14


query_14 = f"""SELECT
  F1.WEEK_DT AS WEEK_DT,
  F1.CHECK_DT AS CHECK_DT,
  F1.LOCATION_ID AS LOCATION_ID,
  F1.STORE_NBR AS STORE_NBR,
  F1.STATE_CD AS STATE_CD,
  F1.BUSN_TYPE AS BUSN_TYPE,
  F1.EXCH_RATE_PCNT AS EXCH_RATE_PCNT,
  F1.TTL_HOTEL_SALES AS TTL_HOTEL_SALES,
  F1.VARIABLE_FACTOR AS VARIABLE_FACTOR,
  F1.FIXED_HOURS AS FIXED_HOURS,
  L1.START_DT AS START_DT,
  F1.Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  FILTRANS1_12 F1
  INNER JOIN LKPTRANS1_13 L1 ON F1.Monotonically_Increasing_Id = L1.Monotonically_Increasing_Id
WHERE
  ISNULL(L1.START_DT)"""

df_14 = spark.sql(query_14)

df_14.createOrReplaceTempView("FILTRANS_14")

# COMMAND ----------
# DBTITLE 1, EXPTRANS1_15


query_15 = f"""SELECT
  WEEK_DT AS WEEK_DT,
  IFF(
    ISNULL(CHECK_DT),
    ADD_TO_DATE(WEEK_DT, 'DD', 7),
    CHECK_DT
  ) AS PAY_WEEK_DT,
  LOCATION_ID AS LOCATION_ID,
  STATE_CD AS STATE_CD,
  BUSN_TYPE AS BUSN_TYPE,
  TTL_HOTEL_SALES AS TTL_HOTEL_SALES,
  (TTL_HOTEL_SALES * VARIABLE_FACTOR) + FIXED_HOURS AS HOTEL_EARNED_HRS,
  Monotonically_Increasing_Id AS Monotonically_Increasing_Id
FROM
  FILTRANS_14"""

df_15 = spark.sql(query_15)

df_15.createOrReplaceTempView("EXPTRANS1_15")

# COMMAND ----------
# DBTITLE 1, PS2_CA_HTL_EARN_HRS_PRE


spark.sql("""INSERT INTO
  PS2_CA_HTL_EARN_HRS_PRE
SELECT
  WEEK_DT AS WEEK_DT,
  PAY_WEEK_DT AS PAY_WEEK_DT,
  LOCATION_ID AS LOCATION_ID,
  STATE_CD AS STATE_CD,
  BUSN_TYPE AS BUSINESS_TYPE,
  TTL_HOTEL_SALES AS TTL_HOTEL_SALES_AMT,
  HOTEL_EARNED_HRS AS EARNED_HRS
FROM
  EXPTRANS1_15""")

# COMMAND ----------
#Post session variable updation
updateVariable(postVariableAssignment, variablesTableName, mainWorkflowId, parentName, "m_ps2_ca_htl_earn_hrs_pre_DEFAULT")

# COMMAND ----------
#Update Mapping Variables in database.
persistVariables(variablesTableName, "m_ps2_ca_htl_earn_hrs_pre_DEFAULT", mainWorkflowId, parentName)
